{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "122909a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle(Path.cwd() / \"pickles\" /\"parsed.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81184594",
   "metadata": {},
   "source": [
    "Hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b7b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get column names\n",
    "df.columns\n",
    "# initialise dictionary\n",
    "adj_dict = {}\n",
    "# Loops thru each row in the df and gets the spacy doc\n",
    "for index, row in df.iterrows():\n",
    "    print(\"-\"*30)\n",
    "    print(row['title'])\n",
    "    doc = row['parsed']\n",
    "    # Loop thru each word of each spacy doc\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"ADJ\":\n",
    "            adj = token.lemma_\n",
    "            adj_dict[adj] = adj_dict.get(adj, 0) + 1\n",
    "\n",
    "# Convert dictionary to lsit of tuples\n",
    "adj_list = list(adj_dict.items())\n",
    "\n",
    "\n",
    "print(adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9699e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create fake data to test function\n",
    "data = {'title': ['novel1', 'novel2', 'novel3'],\n",
    "        'text': ['there was a pink happy cat',\n",
    "                 'the broccoli was soft green and hot',\n",
    "                 'the athlete went running']}\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "# Add parsed column \n",
    "parsed_list = []\n",
    "for index, row in df.iterrows():\n",
    "    parsed_obj = nlp(row['text'])\n",
    "    parsed_list.append(parsed_obj)\n",
    "    \n",
    "df['parsed'] = parsed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8d52e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     /Users/enmanuelmoreno/nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sense_and_Sensibility:\n",
      "\t{('hear', 'I'): 32}\n",
      "\t{('hear', 'you'): 19}\n",
      "\t{('hear', 'she'): 14}\n",
      "\t{('hear', 'they'): 6}\n",
      "\t{('hear', 'Elinor'): 6}\n",
      "\t{('hear', 'he'): 6}\n",
      "\t{('hear', 'Jennings'): 3}\n",
      "\t{('hear', 'we'): 2}\n",
      "\t{('hear', 'Brandon'): 1}\n",
      "\t{('hear', 'both'): 1}\n",
      "North_and_South:\n",
      "\t{('hear', 'she'): 59}\n",
      "\t{('hear', 'I'): 47}\n",
      "\t{('hear', 'he'): 23}\n",
      "\t{('hear', 'you'): 15}\n",
      "\t{('hear', 'they'): 13}\n",
      "\t{('hear', 'Margaret'): 10}\n",
      "\t{('hear', 'we'): 5}\n",
      "\t{('hear', 'Thornton'): 3}\n",
      "\t{('hear', 'who'): 3}\n",
      "\t{('hear', 'yo'): 2}\n",
      "A_Tale_of_Two_Cities:\n",
      "\t{('hear', 'I'): 23}\n",
      "\t{('hear', 'he'): 19}\n",
      "\t{('hear', 'you'): 12}\n",
      "\t{('hear', 'she'): 11}\n",
      "\t{('hear', 'they'): 5}\n",
      "\t{('hear', 'Monseigneur'): 2}\n",
      "\t{('hear', 'one'): 1}\n",
      "\t{('hear', 'Jerry'): 1}\n",
      "\t{('hear', 'D’ye'): 1}\n",
      "\t{('hear', 'we'): 1}\n",
      "Erewhon:\n",
      "\t{('hear', 'I'): 38}\n",
      "\t{('hear', 'he'): 4}\n",
      "\t{('hear', 'they'): 3}\n",
      "\t{('hear', 'she'): 2}\n",
      "\t{('hear', 'we'): 1}\n",
      "\t{('hear', 'who'): 1}\n",
      "\t{('hear', 'destruction'): 1}\n",
      "\t{('hear', 'machine'): 1}\n",
      "\t{('hear', 'one'): 1}\n",
      "The_American:\n",
      "\t{('hear', 'he'): 17}\n",
      "\t{('hear', 'I'): 14}\n",
      "\t{('hear', 'you'): 10}\n",
      "\t{('hear', 'she'): 5}\n",
      "\t{('hear', 'Newman'): 4}\n",
      "\t{('hear', 'they'): 2}\n",
      "\t{('hear', 'we'): 2}\n",
      "\t{('hear', 'who'): 1}\n",
      "\t{('hear', 'one'): 1}\n",
      "\t{('hear', 'Valentin'): 1}\n",
      "Dorian_Gray:\n",
      "\t{('hear', 'I'): 24}\n",
      "\t{('hear', 'he'): 16}\n",
      "\t{('hear', 'one'): 3}\n",
      "\t{('hear', 'you'): 3}\n",
      "\t{('hear', 'people'): 1}\n",
      "\t{('hear', 'lover'): 1}\n",
      "\t{('hear', 'hast'): 1}\n",
      "\t{('hear', 'who'): 1}\n",
      "\t{('hear', 'jar'): 1}\n",
      "\t{('hear', 'Dorian'): 1}\n",
      "Tess_of_the_DUrbervilles:\n",
      "\t{('hear', 'she'): 37}\n",
      "\t{('hear', 'I'): 20}\n",
      "\t{('hear', 'they'): 12}\n",
      "\t{('hear', 'you'): 8}\n",
      "\t{('hear', 'he'): 6}\n",
      "\t{('hear', 'who'): 6}\n",
      "\t{('hear', 'Tess'): 5}\n",
      "\t{('hear', 'Clare'): 3}\n",
      "\t{('hear', 'lady'): 2}\n",
      "\t{('hear', 'queen'): 1}\n",
      "The_Golden_Bowl:\n",
      "\t{('hear', 'she'): 16}\n",
      "\t{('hear', 'he'): 9}\n",
      "\t{('hear', 'you'): 5}\n",
      "\t{('hear', 'Maggie'): 2}\n",
      "\t{('hear', 'man'): 1}\n",
      "\t{('hear', 'that'): 1}\n",
      "\t{('hear', 'they'): 1}\n",
      "\t{('hear', 'who'): 1}\n",
      "\t{('hear', 'Amerigo'): 1}\n",
      "\t{('hear', 'which'): 1}\n",
      "The_Secret_Garden:\n",
      "\t{('hear', 'I'): 28}\n",
      "\t{('hear', 'she'): 25}\n",
      "\t{('hear', 'he'): 16}\n",
      "\t{('hear', 'you'): 8}\n",
      "\t{('hear', 'we'): 6}\n",
      "\t{('hear', 'Mary'): 3}\n",
      "\t{('hear', 'Lennox'): 2}\n",
      "\t{('hear', 'they'): 2}\n",
      "\t{('hear', 'Colin'): 2}\n",
      "\t{('hear', 'one'): 2}\n",
      "Portrait_of_the_Artist:\n",
      "\t{('hear', 'he'): 61}\n",
      "\t{('hear', 'you'): 12}\n",
      "\t{('hear', 'I'): 9}\n",
      "\t{('hear', 'Stephen'): 5}\n",
      "\t{('hear', 'who'): 2}\n",
      "\t{('hear', 'they'): 1}\n",
      "\t{('hear', 'burst'): 1}\n",
      "\t{('hear', 'listener'): 1}\n",
      "\t{('hear', 'that'): 1}\n",
      "\t{('hear', 'one'): 1}\n",
      "The_Black_Moth:\n",
      "\t{('hear', 'I'): 36}\n",
      "\t{('hear', 'he'): 5}\n",
      "\t{('hear', 'you'): 5}\n",
      "\t{('hear', 'we'): 4}\n",
      "\t{('hear', 'Richard'): 3}\n",
      "\t{('hear', 'she'): 2}\n",
      "\t{('hear', 'Street'): 1}\n",
      "\t{('hear', \"ye've\"): 1}\n",
      "\t{('hear', 'Bettison'): 1}\n",
      "\t{('hear', 'madam'): 1}\n",
      "Orlando:\n",
      "\t{('hear', 'she'): 21}\n",
      "\t{('hear', 'he'): 7}\n",
      "\t{('hear', 'Orlando'): 4}\n",
      "\t{('hear', 'one'): 3}\n",
      "\t{('hear', 'they'): 2}\n",
      "\t{('hear', 'I'): 2}\n",
      "\t{('hear', 'God'): 1}\n",
      "\t{('hear', 'we'): 1}\n",
      "\t{('hear', 'that'): 1}\n",
      "\t{('hear', 'which'): 1}\n",
      "Blood_Meridian:\n",
      "\t{('hear', 'he'): 25}\n",
      "\t{('hear', 'they'): 20}\n",
      "\t{('hear', 'you'): 5}\n",
      "\t{('hear', 'I'): 5}\n",
      "\t{('hear', 'who'): 3}\n",
      "\t{('hear', 'man'): 3}\n",
      "\t{('hear', 'she'): 2}\n",
      "\t{('hear', 'all'): 2}\n",
      "\t{('hear', 'we'): 2}\n",
      "\t{('hear', 'nobody'): 1}\n"
     ]
    }
   ],
   "source": [
    "# Test subject_by_verb_count\n",
    "import importlib\n",
    "import PartOne as po\n",
    "\n",
    "importlib.reload(po)\n",
    "\n",
    "\n",
    "df_mini = df.iloc[[0]]\n",
    "#print(df_mini)\n",
    "out = po.subjects_by_verb_count(df, 'to hear')\n",
    "\n",
    "for title, pair in out.items():\n",
    "    print(f\"{title}:\")\n",
    "    if pair:\n",
    "        for pair_dict in pair:\n",
    "            print(f\"\\t{pair_dict}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
