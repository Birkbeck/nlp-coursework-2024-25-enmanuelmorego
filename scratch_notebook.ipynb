{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0b83d47",
   "metadata": {},
   "source": [
    "### Load Pickled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "122909a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle(Path.cwd() / \"pickles\" /\"parsed.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25442120",
   "metadata": {},
   "source": [
    "### Scratched/Tests scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b7b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get column names\n",
    "df.columns\n",
    "# initialise dictionary\n",
    "adj_dict = {}\n",
    "# Loops thru each row in the df and gets the spacy doc\n",
    "for index, row in df.iterrows():\n",
    "    print(\"-\"*30)\n",
    "    print(row['title'])\n",
    "    doc = row['parsed']\n",
    "    # Loop thru each word of each spacy doc\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"ADJ\":\n",
    "            adj = token.lemma_\n",
    "            adj_dict[adj] = adj_dict.get(adj, 0) + 1\n",
    "\n",
    "# Convert dictionary to lsit of tuples\n",
    "adj_list = list(adj_dict.items())\n",
    "\n",
    "\n",
    "print(adj_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c1037",
   "metadata": {},
   "source": [
    "#### Test subject by verb count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d52e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test subject_by_verb_count\n",
    "import importlib\n",
    "import PartOne as po\n",
    "\n",
    "importlib.reload(po)\n",
    "\n",
    "\n",
    "df_mini = df.iloc[[0]]\n",
    "#print(df_mini)\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    print(row['title'])\n",
    "    for pair in po.subjects_by_verb_count(row['parsed'], 'run'):\n",
    "        print(f\"\\t {pair}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e207afd9",
   "metadata": {},
   "source": [
    "### Developing Pointwise mutual information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1856ee",
   "metadata": {},
   "source": [
    "Use only 1 row of the data frame for development only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e0d29737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title                                            dummy_text\n",
      "text      The cat hears a mouse. The dog hears a noise. ...\n",
      "parsed    (The, cat, hears, a, mouse, ., The, dog, hears...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "df_mini = df.iloc[0]\n",
    "\n",
    "data = [{'title': \"dummy_text\", 'text': 'The cat hears a mouse. The dog hears a noise. The cat hears the dog.'}]\n",
    "\n",
    "df_mini = pd.DataFrame(data)\n",
    "\n",
    "# load your model\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# add parse\n",
    "\n",
    "df_mini['parsed'] = df_mini['text'].apply(nlp)\n",
    "df_mini = df_mini.iloc[0]\n",
    "\n",
    "print(df_mini.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb963a1",
   "metadata": {},
   "source": [
    "#### Create the Subject-Verb pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "67605fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy_text\n",
      "1. Counts of Verbs and Subjects:\n",
      "\t[{('hear', 'cat'): 2}, {('hear', 'dog'): 1}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# count of co occurrence\n",
    "verb = 'hear'\n",
    "verb_subject = po.subjects_by_verb_count(df_mini['parsed'], verb)\n",
    "\n",
    "# for doc in df_mini['parsed']:\n",
    "#     verb_subject = (po.subjects_by_verb_count(doc, \"hear\"))\n",
    "print(df_mini['title'])\n",
    "print(f\"1. Counts of Verbs and Subjects:\\n\\t{verb_subject}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daa6e34",
   "metadata": {},
   "source": [
    "#### Extract unique words from the S-V pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5509b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Extract unique words for total counts: \n",
      "\t{'cat', 'hear', 'dog'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract unique objects\n",
    "unique_w = set()\n",
    "for d in verb_subject:\n",
    "    for k in d.keys():\n",
    "        for ind in k:\n",
    "            unique_w.add(ind)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"2. Extract unique words for total counts: \\n\\t{unique_w}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d871811",
   "metadata": {},
   "source": [
    "#### Count total words, and count of individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b1cfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "cat\n",
      "hear\n",
      "a\n",
      "mouse\n",
      "the\n",
      "dog\n",
      "hear\n",
      "a\n",
      "noise\n",
      "the\n",
      "cat\n",
      "hear\n",
      "the\n",
      "dog\n",
      "3. Total words and total count for existing words: \n",
      "\tTotal words: 15\n",
      "\tTotal count for existing:\n",
      "\t{'cat': 2, 'hear': 3, 'dog': 2}\n"
     ]
    }
   ],
   "source": [
    "# Count word occurrence in whole document, and total tokens in doc\n",
    "total_words = 0\n",
    "# Create and add keys to count the expected words\n",
    "total_existing = {w: 0 for w in unique_w}\n",
    "\n",
    "for token in df_mini['parsed']:\n",
    "\n",
    "    if token.text.isalpha():\n",
    "        total_words += 1\n",
    "        word_lemma = token.lemma_\n",
    "        if word_lemma in total_existing:\n",
    "            total_existing[word_lemma] += 1\n",
    "print(f\"3. Total words and total count for existing words: \\n\\tTotal words: {total_words}\\n\\tTotal count for existing:\\n\\t{total_existing}\")\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e36d18",
   "metadata": {},
   "source": [
    "#### Calculate PPMI for the pair of the top 10 S-V pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "005fa7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: ('hear', 'cat'), PPMI: 2.322\n",
      "Key: ('hear', 'dog'), PPMI: 1.322\n",
      "[(('hear', 'cat'), 2.322), (('hear', 'dog'), 1.322)]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# Probability of the verb (context)\n",
    "p_c = total_existing[verb]/total_words\n",
    "ppmi_dict = {}\n",
    "# Loop over the dictionary of the 10 s-v pairs\n",
    "for d in verb_subject:\n",
    "    for key, value in d.items():\n",
    "        # probability of the pair verb-subject\n",
    "        p_wc = value/total_words\n",
    "        # Probability of the subject (word)\n",
    "        p_w = total_existing[key[1]]/total_words\n",
    "        # Calculate PMI\n",
    "        pmi = p_wc/(p_w * p_c)\n",
    "        pmi = math.log2(pmi)\n",
    "        ppmi = max(pmi,0)\n",
    "        print(f\"Key: {key}, PPMI: {round(ppmi,3)}\")\n",
    "        # Add value to final dict\n",
    "        ppmi_dict[key] = ppmi_dict.get(key, round(ppmi,3))\n",
    "# Sort final dictionary\n",
    "ppmi_dict = sorted(ppmi_dict.items(), key = lambda item: item[1], reverse = True)\n",
    "\n",
    "print(ppmi_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
