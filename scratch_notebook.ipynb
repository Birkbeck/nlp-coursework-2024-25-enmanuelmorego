{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "122909a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle(Path.cwd() / \"pickles\" /\"parsed.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81184594",
   "metadata": {},
   "source": [
    "Hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b7b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get column names\n",
    "df.columns\n",
    "# initialise dictionary\n",
    "adj_dict = {}\n",
    "# Loops thru each row in the df and gets the spacy doc\n",
    "for index, row in df.iterrows():\n",
    "    print(\"-\"*30)\n",
    "    print(row['title'])\n",
    "    doc = row['parsed']\n",
    "    # Loop thru each word of each spacy doc\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"ADJ\":\n",
    "            adj = token.lemma_\n",
    "            adj_dict[adj] = adj_dict.get(adj, 0) + 1\n",
    "\n",
    "# Convert dictionary to lsit of tuples\n",
    "adj_list = list(adj_dict.items())\n",
    "\n",
    "\n",
    "print(adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9699e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create fake data to test function\n",
    "data = {'title': ['novel1', 'novel2', 'novel3'],\n",
    "        'text': ['there was a pink happy cat',\n",
    "                 'the broccoli was soft green and hot',\n",
    "                 'the athlete went running']}\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "# Add parsed column \n",
    "parsed_list = []\n",
    "for index, row in df.iterrows():\n",
    "    parsed_obj = nlp(row['text'])\n",
    "    parsed_list.append(parsed_obj)\n",
    "    \n",
    "df['parsed'] = parsed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8d52e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test subject_by_verb_count\n",
    "import PartOne as po\n",
    "df_mini = df.iloc[[0]]\n",
    "#print(df_mini)\n",
    "out = po.subjects_by_verb_count(df_mini, 'to hear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170be224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
