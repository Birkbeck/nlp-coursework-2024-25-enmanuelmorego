{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f596f013",
   "metadata": {},
   "source": [
    "# Part Two"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904a28c9",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134796c9",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "670483ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import re\n",
    "from transformers import BertTokenizerFast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3808e0e0",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7404d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_speeches_csv(path=Path.cwd() / \"texts\" / \"p2-texts\"):\n",
    "    '''\n",
    "    Function to load csv files into pandas data frames\n",
    "\n",
    "    Args:\n",
    "        Function defaults to a specific location to search for the files unless otherwise specified\n",
    "\n",
    "    Returns\n",
    "        Pandas data frame\n",
    "    '''\n",
    "    # Extract file name\n",
    "    file = os.listdir(path)[0]\n",
    "    file_load = os.path.join(path, file)\n",
    "\n",
    "    # Read data\n",
    "    df = pd.read_csv(file_load)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaadf89",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a3dbf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speeches_clean(df):\n",
    "    '''\n",
    "    Function that takes a data frame containing speeches, and performs custom cleaning tasks on it\n",
    "    Custom cleaning tasks are:\n",
    "        - Column 'party': replaces all entries 'Labour (Co-op)' with 'Labour'\n",
    "        - Column 'party': removes all values where entry is 'Speaker'\n",
    "        - Column 'party': only keeps the rows of the four most common parties\n",
    "            Find the frequency count for each party, and keep the top 4 only\n",
    "        - Column 'speech_class': removes all rows where value is NOT 'Speech'\n",
    "        - Column 'speech': removes any entries where the length of the speech is less than 1000 characters\n",
    "\n",
    "    Args: \n",
    "        df: Pandas data frame\n",
    "\n",
    "    Returns:\n",
    "        A Pandas data frame, cleaned\n",
    "    '''\n",
    "    # (a).i Clean Labour (Co-op) values\n",
    "    df_cleaned = df.replace('Labour (Co-op)', 'Labour')\n",
    "\n",
    "    # (a).ii Remove rows where 'party' == 'Speaker'\n",
    "    '''Note: Remove speaker rows first, otherwise this will interfere with finding the most common parties'''\n",
    "    df_cleaned = df_cleaned[df_cleaned['party'] != 'Speaker']\n",
    "\n",
    "    # (a).ii Remove rows where the value of 'party' is not one of the 4 most common parties\n",
    "    parties_count = df_cleaned['party'].value_counts().sort_values(ascending=False)\n",
    "    # # Extract the name of the 4 most common parties \n",
    "    top4_parties = parties_count.index[:4].tolist()\n",
    "    # # Filter to top 4 most common parties\n",
    "    df_cleaned2 = df_cleaned[df_cleaned['party'].isin(top4_parties)]\n",
    "\n",
    "    # (a).iii Remove rows where value in 'speech_class' is not 'Speech\n",
    "    df_cleaned2 = df_cleaned2[df_cleaned2['speech_class'] == 'Speech']\n",
    "\n",
    "    return df_cleaned2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8ccf26",
   "metadata": {},
   "source": [
    "### Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "976df2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_pipeline(**kwargs):\n",
    "    '''\n",
    "    Function which processes and build ML models given the speeches data and prepares the data to be fed into ML models:\n",
    "    The pipeline:\n",
    "        Splits into train, test sets\n",
    "        Vectorises the data\n",
    "        Trains a RandomForest Model\n",
    "        Trains a Linear SVM classifer\n",
    "        Extracts the CLassification Report for each model\n",
    "        Macro-Average F1 Score\n",
    "    \n",
    "    Arguments can be passed as key value pairs. Some arguments are mandatory whilst other are optionals. When optional arguments are not provided\n",
    "    the function will use defaul values\n",
    "    Ars:\n",
    "        data (mandatory): A cleaned pandas data frame\n",
    "        ngram (optional): a tuple containing the ngram to consider to pass in the TfidVectorizer function\n",
    "            default value: (1,1) unigrams\n",
    "        stop_words (optional): A string containing the value for the stop_words argument for TfidVectorizer. If set ti 'english', stop words would be removed\n",
    "            default value: None - Stop words would not be removed\n",
    "        class_weights (optional): balances the weight for each class in the model depending on frequency counts\n",
    "\n",
    "    '''\n",
    "    # Extract input parameters\n",
    "    input_dict = kwargs\n",
    "\n",
    "    # Extract data from input\n",
    "    df = input_dict.get('data')\n",
    "    ngram = input_dict.get('ngram', (1,1))\n",
    "    stop_words = input_dict.get('stop_words', None)\n",
    "    tokenizer = input_dict.get('tokenizer', None)\n",
    "    class_weight = input_dict.get('class_weight', None)\n",
    "\n",
    "    # Tokenizer print: \n",
    "    if tokenizer is not None:\n",
    "        token_print = tokenizer.__name__\n",
    "    else:\n",
    "        token_print = tokenizer\n",
    "    print(\"\\nArguments:\")\n",
    "    print(f\"\\tNgram: {ngram}\\n\\tStop words: {stop_words}\\n\\tTokenizer: {token_print}\\n\\tClass Weights: {class_weight}\")\n",
    "\n",
    "    # (b) Generate object that splits data using stratified sampling, and random seed of 26\n",
    "    splitter_obj = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 26) \n",
    "    # Split data\n",
    "    for train_index, test_index in splitter_obj.split(df, df['party']):\n",
    "        train = df.iloc[train_index]\n",
    "        test = df.iloc[test_index]\n",
    "\n",
    "    # (b) Split target in both training and testing set\n",
    "    y_train, y_test = train['party'], test['party']\n",
    "\n",
    "    # (b) Create vectorised data for x objects\n",
    "    '''\n",
    "    Max features set to 3000\n",
    "    stop_words, ngram = defined by parameters when function is called\n",
    "    '''\n",
    "    vectorizer = TfidfVectorizer(max_features = 3000, \n",
    "                                 stop_words=stop_words, \n",
    "                                 ngram_range = ngram,\n",
    "                                 tokenizer = tokenizer)\n",
    "    x_train = vectorizer.fit_transform(train['speech'])\n",
    "    x_test = vectorizer.transform(test['speech'])\n",
    "\n",
    "    # (c) Train random forest\n",
    "    random_forest = RandomForestClassifier(n_estimators=300, n_jobs = -1, class_weight=class_weight) \n",
    "    random_forest.fit(x_train, y_train)\n",
    "    random_forest_y_predict = random_forest.predict(x_test)\n",
    "\n",
    "    # (c) Train SVM\n",
    "    svm = LinearSVC(class_weight=class_weight)\n",
    "    svm.fit(x_train, y_train)\n",
    "    svm_y_predict = svm.predict(x_test)\n",
    "\n",
    "    # Get label names\n",
    "    target_names = y_test.unique()\n",
    "\n",
    "    # Results section \n",
    "    print(f\"{\"=\"*20} Random Forest Performance {\"=\"*20}\")\n",
    "    rf_cr = classification_report(y_test, random_forest_y_predict, target_names = target_names, output_dict = True)\n",
    "    print(classification_report(y_test, random_forest_y_predict, target_names = target_names))\n",
    "\n",
    "    print(f\"{\"=\"*20} SVC Performance {\"=\"*20}\")\n",
    "    svc_cr = classification_report(y_test, svm_y_predict, target_names = target_names, output_dict = True)\n",
    "    print(classification_report(y_test, svm_y_predict, target_names = target_names))\n",
    "\n",
    "    return {'rf': rf_cr, 'svc': svc_cr}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf240696",
   "metadata": {},
   "source": [
    "### Custom Tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4865d6a",
   "metadata": {},
   "source": [
    "#### Basic Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4e1633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer_basic(text):\n",
    "    '''\n",
    "    Basic tokenizer:\n",
    "        Removes special break characters, such as \\n, \\t etc\n",
    "        Removes any extra white spaces \n",
    "        Uses nltk word tokenizer to split the words into objects\n",
    "        Only keeps alphabetical objects, ignores numeric and punctuation marks\n",
    "        It keeps enligh stop words\n",
    "    '''\n",
    "    # Clean the text. Remove special characters, such as \\n, \\t etc and extra white spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    return [token for token in tokens if token.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d3f025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'a', 'text', 'to', 'test', 'the', 'tokenizer', 'we', 'add', 'contractions', 'such', 'as', 'dont', 'wo', 'and', 'punctuation', 'to', 'test', 'how', 'the', 'tokenizer', 'handles', 'these', 'tokenizing', 'ml', 'also', 'we', 'check', 'for', 'prime', 'minister', 'the', 'speaker', 'mr', 'speaker', 'and', 'see', 'how', 'these', 'are', 'treated', 'too', 'along', 'with', 'numeric', 'values']\n"
     ]
    }
   ],
   "source": [
    "'''Test tokenizer\n",
    "    - How does it handle contractions: Don't, dont, let's, lets\n",
    "    - How does it handle name objects: Prime Minister, Chris, The Conservative Party\n",
    "    - Special characters: \\n\\t\n",
    "'''\n",
    "test_text = \"test tokenizer\\n\\t. contractions!, SUCH as dont, won't, co-operate and punctuation? how the tokenizer handles these? #tokenizing #ml. Also, we check for Prime Minister, the speaker, mr Speaker and see how these are treated too, along with numeric values 1000 1,000 01/01/2020\"\n",
    "\n",
    "print(my_tokenizer_basic(test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212a6314",
   "metadata": {},
   "source": [
    "#### Sentence Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9e7640",
   "metadata": {},
   "source": [
    "The function below tries a sentence tokenizer. By capturing the full embedded meaning of a sentence instead of a word itself, it is hoped that the model has access to more contextual information and might be able to better predict party based on speech. It is possible that sentences can carry more contextual information than specific words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c1fe02ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer_sentence(text):\n",
    "    '''\n",
    "    Sentence tokenizer:\n",
    "        Removes special break characters, such as \\n, \\t etc\n",
    "        Removes any extra white spaces \n",
    "        Uses nltk sentence tokenizer to split the senteces into objects\n",
    "    '''\n",
    "    # Clean the text. Remove special characters, such as \\n, \\t etc and extra white spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    return sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63ce6ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is a text to test the tokenizer .', \"We add contractions!, such as dont, won't, co-operate and punctuation?\", 'to test how the tokenizer handles these #tokenizing #ml.', 'Also, we check for Prime Minister, the speaker, mr Speaker and see how these are treated too, along with numeric values 1000 1,000 01/01/2020']\n"
     ]
    }
   ],
   "source": [
    "# Test tokenizer\n",
    "print(my_tokenizer_sentence(test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54d9019",
   "metadata": {},
   "source": [
    "## Program / Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c88295",
   "metadata": {},
   "source": [
    "### Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8d92e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36223, 8)\n"
     ]
    }
   ],
   "source": [
    " # Load speeches data frame\n",
    "df = read_speeches_csv()\n",
    "# Clean data frame\n",
    "df_cleaned = speeches_clean(df)\n",
    "# Print dimensions\n",
    "print(df_cleaned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c1a24e",
   "metadata": {},
   "source": [
    "See the class distribution below. It appears that the dataset is imbalanced, in the sense that there is a vast majority of entries for the Conservative party, and a very small proportion of entries for Liberal Democrat. This can have an impact on the classifiers, and should be addressed.\n",
    "\n",
    "SK_Learn provides the class_weight argument, which can be passed to our models. By providing the value 'balanced', the model builds a dictionary where the weights are proportional to the class (similar idea to stratified sampling, in the way that we don't want to over-represent a particular party simply because it appears more often)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c72bf914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "party\n",
      "Conservative               25079\n",
      "Labour                      8038\n",
      "Scottish National Party     2303\n",
      "Liberal Democrat             803\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_cleaned['party'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beca9905",
   "metadata": {},
   "source": [
    "### Train and test ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d91d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to record the Macro Avg F1 score for each tested model\n",
    "f1_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ef754d",
   "metadata": {},
   "source": [
    "#### Model set 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2bb5bc",
   "metadata": {},
   "source": [
    "Train a Random Forest Model and SVM linear Kernel model:\n",
    "\n",
    "    Remove English stop word: Yes\n",
    "    Ngram: unigram only\n",
    "    Tokenizer: Default\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b62231c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arguments:\n",
      "\tNgram: (1, 1)\n",
      "\tStop words: english\n",
      "\tTokenizer: None\n",
      "\tClass Weights: None\n",
      "==================== Random Forest Performance ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                 Labour       0.80      0.97      0.88      5016\n",
      "           Conservative       0.71      0.45      0.56      1608\n",
      "Scottish National Party       0.00      0.00      0.00       160\n",
      "       Liberal Democrat       0.85      0.21      0.34       461\n",
      "\n",
      "               accuracy                           0.79      7245\n",
      "              macro avg       0.59      0.41      0.44      7245\n",
      "           weighted avg       0.77      0.79      0.75      7245\n",
      "\n",
      "==================== SVC Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                 Labour       0.85      0.93      0.89      5016\n",
      "           Conservative       0.65      0.60      0.62      1608\n",
      "Scottish National Party       0.61      0.11      0.18       160\n",
      "       Liberal Democrat       0.63      0.37      0.47       461\n",
      "\n",
      "               accuracy                           0.80      7245\n",
      "              macro avg       0.68      0.50      0.54      7245\n",
      "           weighted avg       0.79      0.80      0.78      7245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "section_c = ml_pipeline(data = df_cleaned, stop_words = 'english')\n",
    "# Save results into a dictionary\n",
    "f1_results['f1_ma_rf_unigram'] =  round(section_c['rf']['macro avg']['f1-score'] ,2)\n",
    "f1_results['f1_ma_svc_unigram'] = round(section_c['svc']['macro avg']['f1-score'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "deea5cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arguments:\n",
      "\tNgram: (1, 1)\n",
      "\tStop words: english\n",
      "\tTokenizer: None\n",
      "\tClass Weights: balanced\n",
      "==================== Random Forest Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                 Labour       0.81      0.94      0.87      5016\n",
      "           Conservative       0.65      0.49      0.56      1608\n",
      "Scottish National Party       0.00      0.00      0.00       160\n",
      "       Liberal Democrat       0.65      0.33      0.44       461\n",
      "\n",
      "               accuracy                           0.78      7245\n",
      "              macro avg       0.53      0.44      0.47      7245\n",
      "           weighted avg       0.75      0.78      0.75      7245\n",
      "\n",
      "==================== SVC Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                 Labour       0.89      0.85      0.87      5016\n",
      "           Conservative       0.61      0.64      0.63      1608\n",
      "Scottish National Party       0.21      0.27      0.24       160\n",
      "       Liberal Democrat       0.41      0.51      0.46       461\n",
      "\n",
      "               accuracy                           0.77      7245\n",
      "              macro avg       0.53      0.57      0.55      7245\n",
      "           weighted avg       0.78      0.77      0.78      7245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "section_c_balanced = ml_pipeline(data = df_cleaned, stop_words = 'english', class_weight = 'balanced')\n",
    "# Save results into a dictionary\n",
    "f1_results['f1_ma_rf_unigram_balanced'] =  round(section_c_balanced['rf']['macro avg']['f1-score'] ,2)\n",
    "f1_results['f1_ma_svc_unigram_balanced'] = round(section_c_balanced['svc']['macro avg']['f1-score'], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f7cf60",
   "metadata": {},
   "source": [
    "#### Model Set 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55b9eba",
   "metadata": {},
   "source": [
    "Train a Random Forest Model and SVM linear Kernel model:\n",
    "\n",
    "    Remove English stop word: Yes\n",
    "    Ngram: unigram, bi-gram and tri-grams\n",
    "    Tokenizer: Default\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8f6a784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arguments:\n",
      "\tNgram: (1, 3)\n",
      "\tStop words: english\n",
      "\tTokenizer: None\n",
      "\tClass Weights: None\n",
      "==================== Random Forest Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                 Labour       0.81      0.96      0.88      5016\n",
      "           Conservative       0.70      0.49      0.58      1608\n",
      "Scottish National Party       0.00      0.00      0.00       160\n",
      "       Liberal Democrat       0.86      0.24      0.37       461\n",
      "\n",
      "               accuracy                           0.79      7245\n",
      "              macro avg       0.59      0.42      0.46      7245\n",
      "           weighted avg       0.77      0.79      0.76      7245\n",
      "\n",
      "==================== SVC Performance ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                 Labour       0.85      0.93      0.89      5016\n",
      "           Conservative       0.65      0.61      0.63      1608\n",
      "Scottish National Party       0.58      0.09      0.16       160\n",
      "       Liberal Democrat       0.67      0.41      0.50       461\n",
      "\n",
      "               accuracy                           0.80      7245\n",
      "              macro avg       0.69      0.51      0.55      7245\n",
      "           weighted avg       0.79      0.80      0.79      7245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "section_d = ml_pipeline(data = df_cleaned, ngram = (1,3), stop_words = 'english')\n",
    "# Save results into a dictionary\n",
    "f1_results['f1_ma_rf_uni_bi_trigrams'] =  round(section_d['rf']['macro avg']['f1-score'] ,2)\n",
    "f1_results['f1_ma_svc_uni_bi_trigrams'] = round(section_d['svc']['macro avg']['f1-score'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7f2ea03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arguments:\n",
      "\tNgram: (1, 3)\n",
      "\tStop words: english\n",
      "\tTokenizer: None\n",
      "\tClass Weights: balanced\n",
      "==================== Random Forest Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                 Labour       0.82      0.93      0.87      5016\n",
      "           Conservative       0.65      0.52      0.58      1608\n",
      "Scottish National Party       0.00      0.00      0.00       160\n",
      "       Liberal Democrat       0.66      0.40      0.49       461\n",
      "\n",
      "               accuracy                           0.78      7245\n",
      "              macro avg       0.53      0.46      0.49      7245\n",
      "           weighted avg       0.75      0.78      0.76      7245\n",
      "\n",
      "==================== SVC Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                 Labour       0.89      0.85      0.87      5016\n",
      "           Conservative       0.61      0.65      0.63      1608\n",
      "Scottish National Party       0.23      0.29      0.25       160\n",
      "       Liberal Democrat       0.42      0.52      0.46       461\n",
      "\n",
      "               accuracy                           0.77      7245\n",
      "              macro avg       0.54      0.58      0.55      7245\n",
      "           weighted avg       0.79      0.77      0.78      7245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "section_d_balanced = ml_pipeline(data = df_cleaned, ngram = (1,3), stop_words = 'english', class_weight = 'balanced')\n",
    "# Save results into a dictionary\n",
    "f1_results['f1_ma_rf_uni_bi_trigrams_balanced'] =  round(section_d_balanced['rf']['macro avg']['f1-score'] ,2)\n",
    "f1_results['f1_ma_svc_uni_bi_trigrams_balanced'] = round(section_d_balanced['svc']['macro avg']['f1-score'], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a782cab7",
   "metadata": {},
   "source": [
    "### Custom Tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508aafcb",
   "metadata": {},
   "source": [
    "**Basic Tokenizer**\n",
    "\n",
    "`my_tokenizer_basic`\n",
    "\n",
    "- Removes special break characters, such as \\n, \\t etc\n",
    "- Removes any extra white spaces \n",
    "- Uses `nltk` word tokenizer to split the words into objects\n",
    "- Only keeps alphabetical objects, ignores numeric and punctuation marks\n",
    "- It keeps English stop words\n",
    "\n",
    "From the metrics below, we can see that this tokenizer did not improve performance on the model. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "538f5c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arguments:\n",
      "\tNgram: (1, 3)\n",
      "\tStop words: None\n",
      "\tTokenizer: my_tokenizer_basic\n",
      "\tClass Weights: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Random Forest Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                 Labour       0.81      0.96      0.88      5016\n",
      "           Conservative       0.67      0.51      0.58      1608\n",
      "Scottish National Party       1.00      0.01      0.01       160\n",
      "       Liberal Democrat       0.87      0.20      0.32       461\n",
      "\n",
      "               accuracy                           0.79      7245\n",
      "              macro avg       0.84      0.42      0.45      7245\n",
      "           weighted avg       0.79      0.79      0.76      7245\n",
      "\n",
      "==================== SVC Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                 Labour       0.86      0.93      0.89      5016\n",
      "           Conservative       0.66      0.63      0.65      1608\n",
      "Scottish National Party       0.33      0.03      0.06       160\n",
      "       Liberal Democrat       0.66      0.41      0.51       461\n",
      "\n",
      "               accuracy                           0.81      7245\n",
      "              macro avg       0.63      0.50      0.53      7245\n",
      "           weighted avg       0.79      0.81      0.79      7245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "section_e_basic_t =  ml_pipeline(data = df_cleaned, ngram = (1,3), tokenizer = my_tokenizer_basic, class_weigth='balanced')\n",
    "f1_results['f1_ma_rf_uni_bi_trigrams_basictoken'] =  round(section_e_basic_t['rf']['macro avg']['f1-score'] ,2)\n",
    "f1_results['f1_ma_svc_uni_bi_trigrams_basictoken'] = round(section_e_basic_t['svc']['macro avg']['f1-score'], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a1da2c",
   "metadata": {},
   "source": [
    "**Sentence Tokenizer**\n",
    "\n",
    "Using a sentence tokenizer produced worse results than previous tokenizers. A potential reason is that splitting the text by sentences instead of words generates a lower proportion of unique values. There will be less repeated sentences than repeated words, therefore this reduces the dimensionality and data availability for the model to actually learn from the data, given that with less repetition of token_x, label_x pairs, it becomes more difficult to the model to generalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb65d46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arguments:\n",
      "\tNgram: (1, 1)\n",
      "\tStop words: None\n",
      "\tTokenizer: my_tokenizer_sentence\n",
      "\tClass Weights: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Random Forest Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                 Labour       0.70      0.99      0.82      5016\n",
      "           Conservative       0.52      0.06      0.11      1608\n",
      "Scottish National Party       0.18      0.01      0.02       160\n",
      "       Liberal Democrat       0.47      0.03      0.06       461\n",
      "\n",
      "               accuracy                           0.70      7245\n",
      "              macro avg       0.47      0.27      0.25      7245\n",
      "           weighted avg       0.64      0.70      0.60      7245\n",
      "\n",
      "==================== SVC Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                 Labour       0.70      0.99      0.82      5016\n",
      "           Conservative       0.53      0.06      0.10      1608\n",
      "Scottish National Party       0.33      0.01      0.02       160\n",
      "       Liberal Democrat       0.41      0.03      0.06       461\n",
      "\n",
      "               accuracy                           0.70      7245\n",
      "              macro avg       0.49      0.27      0.25      7245\n",
      "           weighted avg       0.64      0.70      0.60      7245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "section_e_sentence_t =  ml_pipeline(data = df_cleaned, ngram = (1,1), tokenizer = my_tokenizer_sentence, class_weigth='balanced')\n",
    "f1_results['f1_ma_rf_uni_bi_trigrams_sentencetoken'] =  round(section_e_sentence_t['rf']['macro avg']['f1-score'] ,2)\n",
    "f1_results['f1_ma_svc_uni_bi_trigrams_sentencetoken'] = round(section_e_sentence_t['svc']['macro avg']['f1-score'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74fc4c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Macro Avg Score f1_ma_rf_unigram                         Value:   0.44\n",
      "F1 Macro Avg Score f1_ma_svc_unigram                        Value:   0.54\n",
      "F1 Macro Avg Score f1_ma_rf_unigram_balanced                Value:   0.47\n",
      "F1 Macro Avg Score f1_ma_svc_unigram_balanced               Value:   0.55\n",
      "F1 Macro Avg Score f1_ma_rf_uni_bi_trigrams                 Value:   0.46\n",
      "F1 Macro Avg Score f1_ma_svc_uni_bi_trigrams                Value:   0.55\n",
      "F1 Macro Avg Score f1_ma_rf_uni_bi_trigrams_balanced        Value:   0.49\n",
      "F1 Macro Avg Score f1_ma_svc_uni_bi_trigrams_balanced       Value:   0.55\n",
      "F1 Macro Avg Score f1_ma_rf_uni_bi_trigrams_basictoken      Value:   0.45\n",
      "F1 Macro Avg Score f1_ma_svc_uni_bi_trigrams_basictoken     Value:   0.53\n",
      "F1 Macro Avg Score f1_ma_rf_uni_bi_trigrams_sentencetoken   Value:   0.25\n",
      "F1 Macro Avg Score f1_ma_svc_uni_bi_trigrams_sentencetoken  Value:   0.25\n"
     ]
    }
   ],
   "source": [
    "for key, value in f1_results.items():\n",
    "    print(f\"F1 Macro Avg Score {key:<40} Value: {value:6.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
