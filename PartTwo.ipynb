{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f596f013",
   "metadata": {},
   "source": [
    "# Part Two"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904a28c9",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134796c9",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "670483ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "import contractions\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.tokenizer import Tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3808e0e0",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7404d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_speeches_csv(path=Path.cwd() / \"texts\" / \"p2-texts\"):\n",
    "    '''\n",
    "    Function to load csv files into a pandas data frame\n",
    "\n",
    "    Args:\n",
    "        Function defaults to a specific location to search for the files unless otherwise specified\n",
    "\n",
    "    Returns\n",
    "        Pandas data frame\n",
    "    '''\n",
    "    # Extract file name\n",
    "    file = os.listdir(path)[0]\n",
    "    file_load = os.path.join(path, file)\n",
    "\n",
    "    # Read data\n",
    "    df = pd.read_csv(file_load)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaadf89",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7a3dbf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speeches_clean(df):\n",
    "    '''\n",
    "    Function that takes a data frame containing speeches, and performs custom cleaning tasks on it\n",
    "    Custom cleaning tasks are:\n",
    "        - Column 'party': replaces all entries 'Labour (Co-op)' with 'Labour'\n",
    "        - Column 'party': removes all values where entry is 'Speaker'\n",
    "        - Column 'party': only keeps the rows of the four most common parties\n",
    "                          Finds the frequency count for each party, and keep the top 4 only\n",
    "        - Column 'speech_class': removes all rows where value is NOT 'Speech'\n",
    "        - Column 'speech': removes any entries where the length of the speech is less than 1000 characters\n",
    "\n",
    "    Args: \n",
    "        df: Pandas data frame\n",
    "\n",
    "    Returns:\n",
    "        A Pandas data frame, cleaned\n",
    "    '''\n",
    "    # (a).i Clean Labour (Co-op) values\n",
    "    df_cleaned = df.replace('Labour (Co-op)', 'Labour')\n",
    "\n",
    "    # (a).ii Remove rows where 'party' == 'Speaker'\n",
    "    '''Note: Remove speaker rows first, otherwise this will interfere with finding the most common parties'''\n",
    "    df_cleaned = df_cleaned[df_cleaned['party'] != 'Speaker']\n",
    "\n",
    "    # (a).ii Remove rows where the value of 'party' is not one of the 4 most common parties\n",
    "    parties_count = df_cleaned['party'].value_counts().sort_values(ascending=False)\n",
    "    # # Extract the name of the 4 most common parties \n",
    "    top4_parties = parties_count.index[:4].tolist()\n",
    "    # # Filter to top 4 most common parties\n",
    "    df_cleaned2 = df_cleaned[df_cleaned['party'].isin(top4_parties)]\n",
    "\n",
    "    # (a).iii Remove rows where value in 'speech_class' is not 'Speech\n",
    "    df_cleaned2 = df_cleaned2[df_cleaned2['speech_class'] == 'Speech']\n",
    "\n",
    "    # (a).iv Remove rows where the text in speech columns is less than 1000\n",
    "    df_out = df_cleaned2[df_cleaned2['speech'].str.len() >= 1000]\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8ccf26",
   "metadata": {},
   "source": [
    "### Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "976df2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_pipeline(**kwargs):\n",
    "    '''\n",
    "    Function which processes and build ML models given the speeches data and prepares the data to be fed into ML models:\n",
    "    The pipeline:\n",
    "        Splits into train, test sets\n",
    "        Vectorises the data\n",
    "        Trains a RandomForest Model\n",
    "        Trains a Linear SVM classifer\n",
    "        Extracts the Classification Report for each model\n",
    "        Extracts the macro-Average F1 Score\n",
    "    \n",
    "    Arguments can be passed as key value pairs. Some arguments are mandatory whilst other are optionals. When optional arguments are not provided\n",
    "    the function will use defaul values\n",
    "    Ars:\n",
    "        data (mandatory): A cleaned pandas data frame\n",
    "        ngram (optional): A tuple containing the ngram to consider to pass in the TfidVectorizer function\n",
    "                          default value: (1,1) unigrams\n",
    "        class_weights (optional): Balances the weight for each class in the model depending on frequency counts\n",
    "        verbose (optional): A boolean object, T/F to determine whether the user wants extra information printed out or not\n",
    "        c_value (optional): A float value to be used as the C parameter for the SVC model. If none is specified, then the function will use default, 1.0\n",
    "\n",
    "    The function prints:\n",
    "        The classification report of each model, which contains the Macro Avg F1 value\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with the classification report for the Random Forest and SVC models \n",
    "        Trained random forest and SVC models\n",
    "\n",
    "    '''\n",
    "    # Extract input parameters\n",
    "    input_dict = kwargs\n",
    "\n",
    "    # Extract data from input\n",
    "    df = input_dict.get('data')\n",
    "    ngram = input_dict.get('ngram', (1,1))\n",
    "    tokenizer = input_dict.get('tokenizer', None)\n",
    "    class_weight = input_dict.get('class_weight', None)\n",
    "    verbose = input_dict.get('verbose', False)\n",
    "    best_model = input_dict.get('best_model', False)\n",
    "    c_value = input_dict.get('c_value', 1.0)\n",
    "\n",
    "    if verbose:\n",
    "        # Tokenizer print object \n",
    "        if tokenizer is not None:\n",
    "            token_print = tokenizer.__name__\n",
    "        else:\n",
    "            token_print = tokenizer\n",
    "        print(\"\\nArguments:\")\n",
    "        print(f\"\\tNgram: {ngram}\\n\\tTokenizer: {token_print}\\n\\tClass Weights: {class_weight}\")\n",
    "\n",
    "    # (b) Generate object that splits data using stratified sampling, and random seed of 26\n",
    "    splitter_obj = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 26) \n",
    "    # Split data\n",
    "    for train_index, test_index in splitter_obj.split(df, df['party']):\n",
    "        train = df.iloc[train_index]\n",
    "        test = df.iloc[test_index]\n",
    "\n",
    "    # (b) Split target in both training and testing set\n",
    "    y_train, y_test = train['party'], test['party']\n",
    "\n",
    "    # (b) Create vectorised data for x objects\n",
    "    vectorizer = TfidfVectorizer(max_features = 3000,    # Parameter set as specified in assignment prompt\n",
    "                                 stop_words='english',   # Parameter set as specified in assignment prompt \n",
    "                                 ngram_range = ngram,    # Adjustable parameter\n",
    "                                 tokenizer = tokenizer)  # Adjustable parameter\n",
    "    x_train = vectorizer.fit_transform(train['speech'])\n",
    "    x_test = vectorizer.transform(test['speech'])\n",
    "\n",
    "    '''=== Section C ==='''\n",
    "    # (c) Train random forest\n",
    "    random_forest = RandomForestClassifier(n_estimators=300,           # Parameter set as specified in assignment prompt\n",
    "                                           n_jobs = -1,                # Parameter set for efficiency and faster processing (uses all CPUs available)\n",
    "                                           class_weight=class_weight)  # Adjustable parameter - assigns weights to classes depending on class frequency, important when data is not balanced \n",
    "    random_forest.fit(x_train, y_train)\n",
    "    random_forest_y_predict = random_forest.predict(x_test)\n",
    "\n",
    "    # (c) Train SVM\n",
    "    svm = LinearSVC(class_weight=class_weight,    # Adjustable parameter - assigns weights to classes depending on class frequency, important when data is not balanced \n",
    "                    C = c_value)    \n",
    "    svm.fit(x_train, y_train)\n",
    "    svm_y_predict = svm.predict(x_test)\n",
    "\n",
    "    # Get label names\n",
    "    target_names = y_test.unique()\n",
    "\n",
    "    # Results section \n",
    "    # # Random Forest\n",
    "    rf_cr = classification_report(y_test, random_forest_y_predict, target_names = target_names, output_dict = True, zero_division = 0)\n",
    "    f1_ma_rf = round(rf_cr['macro avg']['f1-score'], 2)\n",
    "\n",
    "    # # SVM Classifier\n",
    "    svc_cr = classification_report(y_test, svm_y_predict, target_names = target_names, output_dict = True, zero_division = 0)\n",
    "    f1_ma_svc = round(svc_cr['macro avg']['f1-score'], 2)\n",
    "\n",
    "    # print best model only, if parameter given\n",
    "    if best_model:\n",
    "        if f1_ma_svc > f1_ma_rf:\n",
    "             print_models = [('SVC', svm_y_predict, f1_ma_svc)]\n",
    "        else:\n",
    "             print_models = [('Random Forest', random_forest_y_predict, f1_ma_rf)]\n",
    "    # Print both models if best model parameter is False\n",
    "    else:\n",
    "        print_models = [('SVC', svm_y_predict, f1_ma_svc), ('Random Forest', random_forest_y_predict, f1_ma_rf)]\n",
    "\n",
    "    # Print information of models\n",
    "    for model_name, y_predict, f1_score in print_models:\n",
    "        print(f\"{\"=\"*20} {model_name} Performance {\"=\"*20}\")\n",
    "        print(classification_report(y_test, y_predict, target_names = target_names, zero_division = 0))\n",
    "        print(f\"F1 Macro Average Score: {f1_score}\\n\")\n",
    "\n",
    "    return {'rf': rf_cr, 'svc': svc_cr}, svm, random_forest \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf240696",
   "metadata": {},
   "source": [
    "### Custom Tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aa0a35",
   "metadata": {},
   "source": [
    "A few different tokenizers implementations were tested to find the best performing one. See tokenizer functions below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4865d6a",
   "metadata": {},
   "source": [
    "#### Basic Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4e1633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer_basic(text):\n",
    "    '''\n",
    "    Basic tokenizer:\n",
    "        Removes special break characters, such as \\n, \\t etc\n",
    "        Removes any extra white spaces \n",
    "        Uses nltk word tokenizer to split the words into objects\n",
    "        Only keeps alphabetical objects, ignores numeric and punctuation marks\n",
    "    '''\n",
    "    # Clean the text. Remove special characters, such as \\n, \\t etc and extra white spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    return [token for token in tokens if token.isalpha()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe95092",
   "metadata": {},
   "source": [
    "#### Using SpaCy and Named Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce44be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def my_tokenizer_spacy(text):\n",
    "    '''\n",
    "    Tokenizer using SpaCy\n",
    "\n",
    "    - Applies the same cleaning steps as basic_tokenizer()\n",
    "    - It uses the contractions library to amend any contractions found in the texts. For example, it transforms \"cant't\" into \"can not\", \"I've\" into \"I have\", etc\n",
    "    - Searches for Name Entity objects (using SpaCy) and joins them into a single string so Named Entities get their own vector representation\n",
    "        For example, the text may contain \"United Kingdom\" and \"united, we will build a better country\". In this case the word \"united\" would get a count of 2\n",
    "        but the meaning of the actual token \"united\" is different given the context. Using name entity labels, the tokenizer below joins \"United Kingdom\" into\n",
    "        \"unitedkingdom\" so this can be stored as a unique vector, separate to \"united\" thus helping to capture as much context as possible. \n",
    "    - Terms that are not named entities are then cleaned and stored into the list of token (along with the transformed named entities)\n",
    "    - Numbers and punctuation marks are excluded from the output\n",
    "    '''\n",
    "\n",
    "    # clean special chatacters and remove extra spaces \n",
    "    text_trimmed = re.sub(r'\\s+', ' ', text)\n",
    "    # Remove extra spaces and transform to lower case\n",
    "    text_trimmed = text_trimmed.strip()\n",
    "    # Do initial simple split\n",
    "    token_iter = text_trimmed.split()\n",
    "\n",
    "    # fix contractions only for words with '\n",
    "    fixed_contractions = [] \n",
    "    for word in token_iter:\n",
    "        if \"'\" in word:\n",
    "            fixed_contractions.append(contractions.fix(word))\n",
    "        else:\n",
    "            fixed_contractions.append(word)\n",
    "    # Join back to string\n",
    "    text_string = \" \".join(fixed_contractions)\n",
    "\n",
    "    # Pass spacy parser\n",
    "    doc = nlp(text_string)\n",
    "    tokenized = []\n",
    "    processed_token_indices = []\n",
    "    # First, save named entities for accuracy (see text above for explanation)\n",
    "    '''Loop using indeces, and save index number to not double count objects in tokenizer'''\n",
    "    for ent in doc.ents:\n",
    "        # Join named entities \n",
    "        ent_clean = re.sub(r\"[^\\w\\s]\", \"\", ent.text).replace(\" \", \"\").lower()\n",
    "        if ent_clean.isalpha():\n",
    "            tokenized.append(ent_clean)\n",
    "        for token in ent:\n",
    "            processed_token_indices.append(token.i)\n",
    "\n",
    "    # Loop over document to extract words, without double counting the already seen values\n",
    "    for token in doc:\n",
    "        if token.i not in processed_token_indices:\n",
    "        # Clean punctuation marks in words (if any)\n",
    "            cleaned_token = re.sub(r\"[^\\w\\s]\", \"\", token.text)\n",
    "            # Then only append letters\n",
    "            if cleaned_token.isalpha():\n",
    "                tokenized.append(cleaned_token.lower())\n",
    "\n",
    "    return tokenized\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ad8110",
   "metadata": {},
   "source": [
    "#### Using SpaCy and Contractions Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "45d61852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download English library object from SpaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# Create custom tokenizer using the vocabulary in the nlp object\n",
    "my_custom_tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "def my_tokenizer_contractions_clean(text):\n",
    "    '''\n",
    "    Tokenizer using SpaCy\n",
    "\n",
    "    - Applies the same cleaning steps as basic_tokenizer()\n",
    "    - It uses the contractions library to amend any contractions found in the texts. For example, it transforms \"cant't\" into \"can not\", \"I've\" into \"I have\", etc\n",
    "    - Applies spacy Tokenizer to split text into objects\n",
    "    - Numbers and punctuation marks are excluded from the output\n",
    "    '''\n",
    "\n",
    "    # clean special chatacters and remove extra spaces \n",
    "    text_trimmed = re.sub(r'\\s+', ' ', text)\n",
    "    # Remove extra spaces and transform to lower case\n",
    "    text_trimmed = text_trimmed.strip()\n",
    "    # Do initial simple split\n",
    "    token_iter = text_trimmed.split()\n",
    "\n",
    "    # fix contractions only for words with '\n",
    "    fixed_contractions = [] \n",
    "    for word in token_iter:\n",
    "        if \"'\" in word:\n",
    "            fixed_contractions.append(contractions.fix(word))\n",
    "        else:\n",
    "            fixed_contractions.append(word)\n",
    "    # Join back to string\n",
    "    text_string = \" \".join(fixed_contractions)\n",
    "\n",
    "    tokenized = my_custom_tokenizer(text_string)\n",
    "    tokenized_out = []\n",
    "    for token in tokenized:\n",
    "        # Clean punctuation marks in words (if any)\n",
    "        cleaned_token = re.sub(r\"[^\\w\\s]\", \"\", token.text)\n",
    "        if cleaned_token.isalpha():\n",
    "            tokenized_out.append(cleaned_token.lower())\n",
    "\n",
    "    return tokenized_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914e95e9",
   "metadata": {},
   "source": [
    "#### Using the Lemmatized version of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "44355e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_tokenizer_lemma(text):\n",
    "    '''\n",
    "    Tokenizer using SpaCy\n",
    "\n",
    "    - Applies the same cleaning steps as basic_tokenizer()\n",
    "    - It uses the contractions library to amend any contractions found in the texts. For example, it transforms \"cant't\" into \"can not\", \"I've\" into \"I have\", etc\n",
    "    - Instead of taking the word as it appears in the text, it takes the lemma version of it\n",
    "    - Numbers and punctuation marks are excluded from the output\n",
    "    '''\n",
    "\n",
    "    # clean special chatacters and remove extra spaces \n",
    "    text_trimmed = re.sub(r'\\s+', ' ', text)\n",
    "    # Remove extra spaces and transform to lower case\n",
    "    text_trimmed = text_trimmed.strip()\n",
    "\n",
    "    # tokenized = my_custom_tokenizer(text_string)\n",
    "    doc = nlp(text_trimmed)\n",
    "    tokenized_out = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.text.isalpha():\n",
    "            tokenized_out.append(token.lemma_.lower())\n",
    "\n",
    "    return tokenized_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54d9019",
   "metadata": {},
   "source": [
    "## Program / Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c88295",
   "metadata": {},
   "source": [
    "### Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e8d92e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8084, 8)\n"
     ]
    }
   ],
   "source": [
    " # Load speeches data frame\n",
    "df = read_speeches_csv()\n",
    "# Clean data frame\n",
    "df_cleaned = speeches_clean(df)\n",
    "# Print dimensions\n",
    "print(df_cleaned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beca9905",
   "metadata": {},
   "source": [
    "### Train and test ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5d91d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to record the Macro Avg F1 score for each tested model\n",
    "f1_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee56249",
   "metadata": {},
   "source": [
    "#### Section C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ef754d",
   "metadata": {},
   "source": [
    "##### Model set 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2bb5bc",
   "metadata": {},
   "source": [
    "Train a Random Forest Model and SVM linear Kernel model:\n",
    "\n",
    "- Ngram: unigram only\n",
    "- Tokenizer: Default\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2b62231c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== SVC Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.85      0.92      0.88       964\n",
      "Scottish National Party       0.76      0.73      0.74       463\n",
      "                 Labour       1.00      0.22      0.36        54\n",
      "       Liberal Democrat       0.72      0.57      0.64       136\n",
      "\n",
      "               accuracy                           0.81      1617\n",
      "              macro avg       0.83      0.61      0.66      1617\n",
      "           weighted avg       0.81      0.81      0.80      1617\n",
      "\n",
      "F1 Macro Average Score: 0.66\n",
      "\n",
      "==================== Random Forest Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.72      0.97      0.83       964\n",
      "Scottish National Party       0.78      0.46      0.58       463\n",
      "                 Labour       0.00      0.00      0.00        54\n",
      "       Liberal Democrat       0.87      0.29      0.44       136\n",
      "\n",
      "               accuracy                           0.74      1617\n",
      "              macro avg       0.59      0.43      0.46      1617\n",
      "           weighted avg       0.73      0.74      0.70      1617\n",
      "\n",
      "F1 Macro Average Score: 0.46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "section_c, svm_model_c, rf_model_c  = ml_pipeline(data = df_cleaned)\n",
    "# Save results into a dictionary\n",
    "f1_results['f1_ma_rf_unigram'] =  round(section_c['rf']['macro avg']['f1-score'] ,2)\n",
    "f1_results['f1_ma_svc_unigram'] = round(section_c['svc']['macro avg']['f1-score'], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48db1089",
   "metadata": {},
   "source": [
    "#### Section D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f7cf60",
   "metadata": {},
   "source": [
    "##### Model Set 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55b9eba",
   "metadata": {},
   "source": [
    "Train a Random Forest Model and SVM linear Kernel model:\n",
    "\n",
    "- Ngram: unigram, bi-gram and tri-grams\n",
    "- Tokenizer: Default\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c8f6a784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== SVC Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.85      0.92      0.88       964\n",
      "Scottish National Party       0.75      0.73      0.74       463\n",
      "                 Labour       0.90      0.17      0.28        54\n",
      "       Liberal Democrat       0.80      0.63      0.70       136\n",
      "\n",
      "               accuracy                           0.82      1617\n",
      "              macro avg       0.82      0.61      0.65      1617\n",
      "           weighted avg       0.82      0.82      0.81      1617\n",
      "\n",
      "F1 Macro Average Score: 0.65\n",
      "\n",
      "==================== Random Forest Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.73      0.97      0.83       964\n",
      "Scottish National Party       0.75      0.46      0.57       463\n",
      "                 Labour       0.00      0.00      0.00        54\n",
      "       Liberal Democrat       0.84      0.38      0.53       136\n",
      "\n",
      "               accuracy                           0.74      1617\n",
      "              macro avg       0.58      0.45      0.48      1617\n",
      "           weighted avg       0.72      0.74      0.71      1617\n",
      "\n",
      "F1 Macro Average Score: 0.48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "section_d,  svm_model_d, rf_model_d = ml_pipeline(data = df_cleaned, ngram = (1,3))\n",
    "# Save results into a dictionary\n",
    "f1_results['f1_ma_rf_uni_bi_trigrams'] =  round(section_d['rf']['macro avg']['f1-score'] ,2)\n",
    "f1_results['f1_ma_svc_uni_bi_trigrams'] = round(section_d['svc']['macro avg']['f1-score'], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a782cab7",
   "metadata": {},
   "source": [
    "#### Section E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f573e19f",
   "metadata": {},
   "source": [
    "**Spacy/Contractions Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1159c705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== SVC Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.88      0.90      0.89       964\n",
      "Scottish National Party       0.76      0.74      0.75       463\n",
      "                 Labour       0.57      0.44      0.50        54\n",
      "       Liberal Democrat       0.72      0.71      0.72       136\n",
      "\n",
      "               accuracy                           0.82      1617\n",
      "              macro avg       0.73      0.70      0.71      1617\n",
      "           weighted avg       0.82      0.82      0.82      1617\n",
      "\n",
      "F1 Macro Average Score: 0.71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "section_e_mytoken, svm_model_e_mytoken, rf_model__e_mytoken =  ml_pipeline(data = df_cleaned, \n",
    "                                                                           ngram = (1,3), \n",
    "                                                                           tokenizer = my_tokenizer_contractions_clean, \n",
    "                                                                           class_weight='balanced', \n",
    "                                                                           best_model = True,\n",
    "                                                                           c_value = 0.5)\n",
    "\n",
    "f1_results['f1_ma_rf_uni_bi_trigrams_contractcleantoken'] =  round(section_e_mytoken['rf']['macro avg']['f1-score'] ,2)\n",
    "f1_results['f1_ma_svc_uni_bi_trigrams_contractcleantoken'] = round(section_e_mytoken['svc']['macro avg']['f1-score'], 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf4f9f2",
   "metadata": {},
   "source": [
    "### Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead1df04",
   "metadata": {},
   "source": [
    "#### Compare all F1 scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "74fc4c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Macro Avg Score f1_ma_rf_unigram                                   Value:   0.46\n",
      "F1 Macro Avg Score f1_ma_svc_unigram                                  Value:   0.66\n",
      "F1 Macro Avg Score f1_ma_rf_uni_bi_trigrams                           Value:   0.49\n",
      "F1 Macro Avg Score f1_ma_svc_uni_bi_trigrams                          Value:   0.65\n",
      "F1 Macro Avg Score f1_ma_rf_uni_bi_trigrams_contractcleantoken        Value:   0.49\n",
      "F1 Macro Avg Score f1_ma_svc_uni_bi_trigrams_contractcleantoken       Value:   0.70\n"
     ]
    }
   ],
   "source": [
    "for key, value in f1_results.items():\n",
    "    print(f\"F1 Macro Avg Score {key:<50} Value: {value:6.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c925507a",
   "metadata": {},
   "source": [
    "#### Grid Search Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fa8022",
   "metadata": {},
   "source": [
    "Code below was used to find the best hyperparameter for SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fa6db0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#  (b) Generate object that splits data using stratified sampling, and random seed of 26\n",
    "splitter_obj = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 26) \n",
    "# Split data\n",
    "for train_index, test_index in splitter_obj.split(df_cleaned, df_cleaned['party']):\n",
    "    train = df_cleaned.iloc[train_index]\n",
    "    test = df_cleaned.iloc[test_index]\n",
    "# (b) Split target in both training and testing set\n",
    "y_train, y_test = train['party'], test['party']\n",
    "# (b) Create vectorised data for x objects\n",
    "'''\n",
    "Max features set to 3000\n",
    "stop_words, ngram = defined by parameters when function is called\n",
    "'''\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features = 3000, \n",
    "                             stop_words='english', \n",
    "                             ngram_range = (1,3),\n",
    "                             tokenizer = my_tokenizer_contractions_clean)\n",
    "x_train = vectorizer.fit_transform(train['speech'])\n",
    "x_test = vectorizer.transform(test['speech'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e366270e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] END ...............................C=0.1, max_iter=5000; total time=   1.3s\n",
      "[CV] END ...............................C=0.1, max_iter=5000; total time=   1.3s\n",
      "[CV] END ...............................C=0.1, max_iter=5000; total time=   1.2s\n",
      "[CV] END ...............................C=0.1, max_iter=5000; total time=   1.2s\n",
      "[CV] END ...............................C=0.1, max_iter=5000; total time=   1.1s\n",
      "[CV] END ...............................C=0.5, max_iter=5000; total time=   1.3s\n",
      "[CV] END ...............................C=0.5, max_iter=5000; total time=   1.4s\n",
      "[CV] END ...............................C=0.5, max_iter=5000; total time=   1.3s\n",
      "[CV] END ...............................C=0.5, max_iter=5000; total time=   1.0s\n",
      "[CV] END ...............................C=0.5, max_iter=5000; total time=   1.0s\n",
      "[CV] END .................................C=1, max_iter=5000; total time=   1.1s\n",
      "[CV] END .................................C=1, max_iter=5000; total time=   1.1s\n",
      "[CV] END .................................C=1, max_iter=5000; total time=   1.1s\n",
      "[CV] END .................................C=1, max_iter=5000; total time=   1.0s\n",
      "[CV] END .................................C=1, max_iter=5000; total time=   1.0s\n",
      "[CV] END ...............................C=1.5, max_iter=5000; total time=   1.1s\n",
      "[CV] END ...............................C=1.5, max_iter=5000; total time=   1.0s\n",
      "[CV] END ...............................C=1.5, max_iter=5000; total time=   1.0s\n",
      "[CV] END ...............................C=1.5, max_iter=5000; total time=   1.1s\n",
      "[CV] END ...............................C=1.5, max_iter=5000; total time=   1.1s\n",
      "[CV] END .................................C=2, max_iter=5000; total time=   1.1s\n",
      "[CV] END .................................C=2, max_iter=5000; total time=   1.1s\n",
      "[CV] END .................................C=2, max_iter=5000; total time=   1.1s\n",
      "[CV] END .................................C=2, max_iter=5000; total time=   1.1s\n",
      "[CV] END .................................C=2, max_iter=5000; total time=   0.6s\n",
      "\n",
      "=== All macro F1 scores ===\n",
      "C=0.1, macro F1: 0.658\n",
      "C=0.5, macro F1: 0.668\n",
      "C=1, macro F1: 0.664\n",
      "C=1.5, macro F1: 0.660\n",
      "C=2, macro F1: 0.665\n",
      "Best params: {'C': 0.5, 'max_iter': 5000}\n",
      "Best macro F1 (CV): 0.6679662845003971\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.88      0.90      0.89       964\n",
      "                 Labour       0.76      0.74      0.75       463\n",
      "       Liberal Democrat       0.57      0.44      0.50        54\n",
      "Scottish National Party       0.72      0.71      0.72       136\n",
      "\n",
      "               accuracy                           0.82      1617\n",
      "              macro avg       0.73      0.70      0.71      1617\n",
      "           weighted avg       0.82      0.82      0.82      1617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initial options for C\n",
    "c_initial = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "# Fined tuned after initial crossvalidation check\n",
    "c_second = [0.1, 0.5, 1, 1.5, 2]\n",
    "\n",
    "param_grid = [{'C': c_second,\n",
    "               'max_iter': [5000]}]\n",
    "\n",
    "svc = LinearSVC(class_weight='balanced')\n",
    "\n",
    "grid_search = GridSearchCV(estimator = svc,\n",
    "                           param_grid = param_grid,\n",
    "                           scoring = 'f1_macro',\n",
    "                           cv = 5,\n",
    "                           verbose = 2,\n",
    "                           n_jobs = -1)\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "print(\"\\n=== All macro F1 scores ===\")\n",
    "for mean, params in zip(grid_search.cv_results_['mean_test_score'], grid_search.cv_results_['params']):\n",
    "    print(f\"C={params['C']}, macro F1: {mean:.3f}\")\n",
    "\n",
    "print(\"Best params:\", grid_search.best_params_)\n",
    "print(\"Best macro F1 (CV):\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate best model on your held-out test:\n",
    "best_svc = grid_search.best_estimator_\n",
    "y_pred = best_svc.predict(x_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
