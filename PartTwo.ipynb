{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f596f013",
   "metadata": {},
   "source": [
    "# Part Two"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904a28c9",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134796c9",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "670483ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "import contractions\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.tokenizer import Tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3808e0e0",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7404d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_speeches_csv(path=Path.cwd() / \"texts\" / \"p2-texts\"):\n",
    "    '''\n",
    "    Function to load csv files into a pandas data frame\n",
    "\n",
    "    Args:\n",
    "        Function defaults to a specific location to search for the files unless otherwise specified\n",
    "\n",
    "    Returns\n",
    "        Pandas data frame\n",
    "    '''\n",
    "    # Extract file name\n",
    "    file = os.listdir(path)[0]\n",
    "    file_load = os.path.join(path, file)\n",
    "\n",
    "    # Read data\n",
    "    df = pd.read_csv(file_load)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaadf89",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7a3dbf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speeches_clean(df):\n",
    "    '''\n",
    "    Function that takes a data frame containing speeches, and performs custom cleaning tasks on it\n",
    "    Custom cleaning tasks are:\n",
    "        - Column 'party': replaces all entries 'Labour (Co-op)' with 'Labour'\n",
    "        - Column 'party': removes all values where entry is 'Speaker'\n",
    "        - Column 'party': only keeps the rows of the four most common parties\n",
    "                          Finds the frequency count for each party, and keep the top 4 only\n",
    "        - Column 'speech_class': removes all rows where value is NOT 'Speech'\n",
    "        - Column 'speech': removes any entries where the length of the speech is less than 1000 characters\n",
    "\n",
    "    Args: \n",
    "        df: Pandas data frame\n",
    "\n",
    "    Returns:\n",
    "        A Pandas data frame, cleaned\n",
    "    '''\n",
    "    # (a).i Clean Labour (Co-op) values\n",
    "    df_cleaned = df.replace('Labour (Co-op)', 'Labour')\n",
    "\n",
    "    # (a).ii Remove rows where 'party' == 'Speaker'\n",
    "    '''Note: Remove speaker rows first, otherwise this will interfere with finding the most common parties'''\n",
    "    df_cleaned = df_cleaned[df_cleaned['party'] != 'Speaker']\n",
    "\n",
    "    # (a).ii Remove rows where the value of 'party' is not one of the 4 most common parties\n",
    "    parties_count = df_cleaned['party'].value_counts().sort_values(ascending=False)\n",
    "    # # Extract the name of the 4 most common parties \n",
    "    top4_parties = parties_count.index[:4].tolist()\n",
    "    # # Filter to top 4 most common parties\n",
    "    df_cleaned2 = df_cleaned[df_cleaned['party'].isin(top4_parties)]\n",
    "\n",
    "    # (a).iii Remove rows where value in 'speech_class' is not 'Speech\n",
    "    df_cleaned2 = df_cleaned2[df_cleaned2['speech_class'] == 'Speech']\n",
    "\n",
    "    # (a).iv Remove rows where the text in speech columns is less than 1000\n",
    "    df_out = df_cleaned2[df_cleaned2['speech'].str.len() >= 1000]\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8ccf26",
   "metadata": {},
   "source": [
    "### Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "976df2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_pipeline(**kwargs):\n",
    "    '''\n",
    "    Function which processes and build ML models given the speeches data and prepares the data to be fed into ML models:\n",
    "    The pipeline:\n",
    "        Splits into train, test sets\n",
    "        Vectorises the data\n",
    "        Trains a RandomForest Model\n",
    "        Trains a Linear SVM classifer\n",
    "        Extracts the Classification Report for each model\n",
    "        Extracts the macro-Average F1 Score\n",
    "    \n",
    "    Arguments can be passed as key value pairs. Some arguments are mandatory whilst other are optionals. When optional arguments are not provided\n",
    "    the function will use defaul values\n",
    "    Ars:\n",
    "        data (mandatory): A cleaned pandas data frame\n",
    "        ngram (optional): A tuple containing the ngram to consider to pass in the TfidVectorizer function\n",
    "                          default value: (1,1) unigrams\n",
    "        class_weights (optional): Balances the weight for each class in the model depending on frequency counts\n",
    "        verbose (optional): A booles object, T/F to determine whether the user wants extra information printed out or not\n",
    "\n",
    "    The function prints:\n",
    "        The classification report of each model, which contains the Macro Avg F1 value\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with the classification report for the Random Forest and SVC models \n",
    "        Trained random forest and SVC models\n",
    "\n",
    "    '''\n",
    "    # Extract input parameters\n",
    "    input_dict = kwargs\n",
    "\n",
    "    # Extract data from input\n",
    "    df = input_dict.get('data')\n",
    "    ngram = input_dict.get('ngram', (1,1))\n",
    "    tokenizer = input_dict.get('tokenizer', None)\n",
    "    class_weight = input_dict.get('class_weight', None)\n",
    "    verbose = input_dict.get('verbose', False)\n",
    "    best_model = input_dict.get('best_model', False)\n",
    "\n",
    "    if verbose:\n",
    "        # Tokenizer print object \n",
    "        if tokenizer is not None:\n",
    "            token_print = tokenizer.__name__\n",
    "        else:\n",
    "            token_print = tokenizer\n",
    "        print(\"\\nArguments:\")\n",
    "        print(f\"\\tNgram: {ngram}\\n\\tTokenizer: {token_print}\\n\\tClass Weights: {class_weight}\")\n",
    "\n",
    "    # (b) Generate object that splits data using stratified sampling, and random seed of 26\n",
    "    splitter_obj = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 26) \n",
    "    # Split data\n",
    "    for train_index, test_index in splitter_obj.split(df, df['party']):\n",
    "        train = df.iloc[train_index]\n",
    "        test = df.iloc[test_index]\n",
    "\n",
    "    # (b) Split target in both training and testing set\n",
    "    y_train, y_test = train['party'], test['party']\n",
    "\n",
    "    # (b) Create vectorised data for x objects\n",
    "    vectorizer = TfidfVectorizer(max_features = 3000,    # Parameter set as specified in assignment prompt\n",
    "                                 stop_words='english',   # Parameter set as specified in assignment prompt \n",
    "                                 ngram_range = ngram,    # Adjustable parameter\n",
    "                                 tokenizer = tokenizer)  # Adjustable parameter\n",
    "    x_train = vectorizer.fit_transform(train['speech'])\n",
    "    x_test = vectorizer.transform(test['speech'])\n",
    "\n",
    "    '''=== Section C ==='''\n",
    "    # (c) Train random forest\n",
    "    random_forest = RandomForestClassifier(n_estimators=300,           # Parameter set as specified in assignment prompt\n",
    "                                           n_jobs = -1,                # Parameter set for efficiency and faster processing (uses all CPUs available)\n",
    "                                           class_weight=class_weight)  # Adjustable parameter - assigns weights to classes depending on class frequency, important when data is not balanced \n",
    "    random_forest.fit(x_train, y_train)\n",
    "    random_forest_y_predict = random_forest.predict(x_test)\n",
    "\n",
    "    # (c) Train SVM\n",
    "    svm = LinearSVC(class_weight=class_weight)   # Adjustable parameter - assigns weights to classes depending on class frequency, important when data is not balanced  \n",
    "    svm.fit(x_train, y_train)\n",
    "    svm_y_predict = svm.predict(x_test)\n",
    "\n",
    "    # Get label names\n",
    "    target_names = y_test.unique()\n",
    "\n",
    "    # Results section \n",
    "    # # Random Forest\n",
    "    rf_cr = classification_report(y_test, random_forest_y_predict, target_names = target_names, output_dict = True, zero_division = 0)\n",
    "    f1_ma_rf = round(rf_cr['macro avg']['f1-score'], 2)\n",
    "\n",
    "    # # SVM Classifier\n",
    "    svc_cr = classification_report(y_test, svm_y_predict, target_names = target_names, output_dict = True, zero_division = 0)\n",
    "    f1_ma_svc = round(svc_cr['macro avg']['f1-score'], 2)\n",
    "\n",
    "    if best_model:\n",
    "        # Find the best model\n",
    "        svm_best = f1_ma_svc > f1_ma_rf\n",
    "        # print based on test above\n",
    "        if svm_best:\n",
    "               print(f\"{\"=\"*20} SVC Performance {\"=\"*20}\")\n",
    "               print(classification_report(y_test, svm_y_predict, target_names = target_names, zero_division = 0))\n",
    "               print(f\"F1 Macro Average Score: {f1_ma_svc}\\n\")\n",
    "        else: \n",
    "               print(f\"{\"=\"*20} Random Forest Performance {\"=\"*20}\")\n",
    "               print(classification_report(y_test, random_forest_y_predict, target_names = target_names, zero_division = 0))\n",
    "               print(f\"F1 Macro Average Score: {f1_ma_rf}\\n\")\n",
    "    else:\n",
    "\n",
    "        print(f\"{\"=\"*20} Random Forest Performance {\"=\"*20}\")\n",
    "        print(classification_report(y_test, random_forest_y_predict, target_names = target_names, zero_division = 0))\n",
    "        print(f\"F1 Macro Average Score: {f1_ma_rf}\\n\")\n",
    "\n",
    "    \n",
    "        print(f\"{\"=\"*20} SVC Performance {\"=\"*20}\")\n",
    "        print(classification_report(y_test, svm_y_predict, target_names = target_names, zero_division = 0))\n",
    "        print(f\"F1 Macro Average Score: {f1_ma_svc}\\n\")\n",
    "\n",
    "    return {'rf': rf_cr, 'svc': svc_cr}, svm, random_forest \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf240696",
   "metadata": {},
   "source": [
    "### Custom Tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aa0a35",
   "metadata": {},
   "source": [
    "A few different tokenizers implementations were tested to find the best performing one. See tokenizer functions below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4865d6a",
   "metadata": {},
   "source": [
    "#### Basic Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4e1633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer_basic(text):\n",
    "    '''\n",
    "    Basic tokenizer:\n",
    "        Removes special break characters, such as \\n, \\t etc\n",
    "        Removes any extra white spaces \n",
    "        Uses nltk word tokenizer to split the words into objects\n",
    "        Only keeps alphabetical objects, ignores numeric and punctuation marks\n",
    "    '''\n",
    "    # Clean the text. Remove special characters, such as \\n, \\t etc and extra white spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    return [token for token in tokens if token.isalpha()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a8fc2e",
   "metadata": {},
   "source": [
    "From the examples above it seems that we need a tokenizer that provides cleaner data. \n",
    "\n",
    "The tokenizer below attempts to solve the following issues:\n",
    "\n",
    "- Words contractions:\n",
    "    Words like `won't` would be stored in a different vector than `will` and `not`, despite having the same meaning. The tokenizer below uses the `contraction` library to expand these contractions into a uniform output. Anytime `won't` is encountered, it gets transformed to `will not`. This consistency across the corpus might provide more accurate representation and improve the performance of the model.\n",
    "\n",
    "- Named entities:\n",
    "    Names entities like `Prime Minister` would be stored as two vectors, one for `prime` and one for `minister`. If in the corpus the word `prime` appears in a different context, such as a discussion on `prime TV shows`, the word `prime` would get a frequency count of 2, despite these two words having very different meaning given their context. The tokenizer below uses `Spacy` `en_core_web_lg` to detect all name entities, and when found, these are collapsed into a single word, i.e., `primeminister`. The objective is that each time `Prime Minister` appears, it is encoded as the entity of `Prime Minister` and not two separate words. \n",
    "    This should also help with stop words, as `The Church` would become `thechurch` as it refers to a specific entity, thus increasing the resolution and context of stop words as well. \n",
    "\n",
    "- Standard cleaning:\n",
    "    This tokenizer also applies standard cleaning, such as converting all words to lower case, removes punctuation marks and digits. \n",
    "\n",
    "- Stop words:\n",
    "    Stop words are not removed as these might be significant and perhaps could be part of named entities.\n",
    "\n",
    "Unfortunately, this complex tokenization did not add any predictive power to our models. In fact, it performed worse than some simpler tokenizers. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce44be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def my_tokenizer_spacy(text):\n",
    "    '''\n",
    "    Tokenizer using SpaCy\n",
    "\n",
    "    - Applies the same cleaning steps as basic_tokenizer()\n",
    "    - It uses the contractions library to amend any contractions found in the texts. For example, it transforms \"cant't\" into \"can not\", \"I've\" into \"I have\", etc\n",
    "    - Searches for Name Entity objects (using SpaCy) and joins them into a single string so Named Entities get their own vector representation\n",
    "        For example, the text may contain \"United Kingdom\" and \"united, we will build a better country\". In this case the word \"united\" would get a count of 2\n",
    "        but the meaning of the actual token \"united\" is different given the context. Using name entity labels, the tokenizer below joins \"United Kingdom\" into\n",
    "        \"unitedkingdom\" so this can be stored as a unique vector, separate to \"united\" thus helping to capture as much context as possible. \n",
    "    - Terms that are not named entities are then cleaned and stored into the list of token (along with the transformed named entities)\n",
    "    - Numbers and punctuation marks are excluded from the output\n",
    "    '''\n",
    "\n",
    "    # clean special chatacters and remove extra spaces \n",
    "    text_trimmed = re.sub(r'\\s+', ' ', text)\n",
    "    # Remove extra spaces and transform to lower case\n",
    "    text_trimmed = text_trimmed.strip()\n",
    "    # Do initial simple split\n",
    "    token_iter = text_trimmed.split()\n",
    "\n",
    "    # fix contractions only for words with '\n",
    "    fixed_contractions = [] \n",
    "    for word in token_iter:\n",
    "        if \"'\" in word:\n",
    "            fixed_contractions.append(contractions.fix(word))\n",
    "        else:\n",
    "            fixed_contractions.append(word)\n",
    "    # Join back to string\n",
    "    text_string = \" \".join(fixed_contractions)\n",
    "\n",
    "    # Pass spacy parser\n",
    "    doc = nlp(text_string)\n",
    "    tokenized = []\n",
    "    processed_token_indices = []\n",
    "    # First, save named entities for accuracy (see text above for explanation)\n",
    "    '''Loop using indeces, and save index number to not double count objects in tokenizer'''\n",
    "    for ent in doc.ents:\n",
    "        # Join named entities \n",
    "        ent_clean = re.sub(r\"[^\\w\\s]\", \"\", ent.text).replace(\" \", \"\").lower()\n",
    "        if ent_clean.isalpha():\n",
    "            tokenized.append(ent_clean)\n",
    "        for token in ent:\n",
    "            processed_token_indices.append(token.i)\n",
    "\n",
    "    # Loop over document to extract words, without double counting the already seen values\n",
    "    for token in doc:\n",
    "        if token.i not in processed_token_indices:\n",
    "        # Clean punctuation marks in words (if any)\n",
    "            cleaned_token = re.sub(r\"[^\\w\\s]\", \"\", token.text)\n",
    "            # Then only append letters\n",
    "            if cleaned_token.isalpha():\n",
    "                tokenized.append(cleaned_token.lower())\n",
    "\n",
    "    return tokenized\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "45d61852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'tokenizer', 'contractions', 'such', 'as', 'do', 'not', 'will', 'not', 'cooperate', 'and', 'punctuation', 'how', 'the', 'tokenizer', 'handles', 'these', 'tokenizing', 'ml', 'also', 'we', 'check', 'for', 'uk', 'prime', 'minister', 'the', 'speaker', 'mr', 'speaker', 'and', 'see', 'how', 'these', 'are', 'treated', 'too', 'along', 'with', 'numeric', 'values']\n"
     ]
    }
   ],
   "source": [
    "# Download English library object from SpaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# Create custom tokenizer using the vocabulary in the nlp object\n",
    "my_custom_tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "def my_tokenizer_contractions_clean(text):\n",
    "        \n",
    "    # clean special chatacters and remove extra spaces \n",
    "    text_trimmed = re.sub(r'\\s+', ' ', text)\n",
    "    # Remove extra spaces and transform to lower case\n",
    "    text_trimmed = text_trimmed.strip()\n",
    "    # Do initial simple split\n",
    "    token_iter = text_trimmed.split()\n",
    "\n",
    "    # fix contractions only for words with '\n",
    "    fixed_contractions = [] \n",
    "    for word in token_iter:\n",
    "        if \"'\" in word:\n",
    "            fixed_contractions.append(contractions.fix(word))\n",
    "        else:\n",
    "            fixed_contractions.append(word)\n",
    "    # Join back to string\n",
    "    text_string = \" \".join(fixed_contractions)\n",
    "\n",
    "    tokenized = my_custom_tokenizer(text_string)\n",
    "    tokenized_out = []\n",
    "    for token in tokenized:\n",
    "        # Clean punctuation marks in words (if any)\n",
    "        cleaned_token = re.sub(r\"[^\\w\\s]\", \"\", token.text)\n",
    "\n",
    "        if cleaned_token.isalpha():\n",
    "            tokenized_out.append(cleaned_token.lower())\n",
    "\n",
    "    return tokenized_out\n",
    "\n",
    "text = \"test tokenizer\\n\\t. contractions!, SUCH as don't, won't, co-operate and punctuation? how the tokenizer handles these? #tokenizing #ml. Also, we check for U.K. Prime Minister, the speaker, mr Speaker and see how these are treated too, along with numeric values 1000 1,000 01/01/2020\"\n",
    "print(my_tokenizer_contractions_clean(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44355e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'tokenizer', 'contraction', 'such', 'as', 'do', 'will', 'co', 'operate', 'and', 'punctuation', 'how', 'the', 'tokenizer', 'handle', 'these', 'tokenize', 'ml', 'also', 'we', 'check', 'for', 'prime', 'minister', 'the', 'speaker', 'mr', 'speaker', 'and', 'see', 'how', 'these', 'be', 'treat', 'too', 'along', 'with', 'numeric', 'value']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def my_tokenizer_lemma(text):\n",
    "        \n",
    "    # clean special chatacters and remove extra spaces \n",
    "    text_trimmed = re.sub(r'\\s+', ' ', text)\n",
    "    # Remove extra spaces and transform to lower case\n",
    "    text_trimmed = text_trimmed.strip()\n",
    "\n",
    "    # tokenized = my_custom_tokenizer(text_string)\n",
    "    doc = nlp(text_trimmed)\n",
    "    tokenized_out = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.text.isalpha():\n",
    "            tokenized_out.append(token.lemma_.lower())\n",
    "\n",
    "    return tokenized_out\n",
    "\n",
    "text = \"test tokenizer\\n\\t. contractions!, SUCH as don't, won't, co-operate and punctuation? how the tokenizer handles these? #tokenizing #ml. Also, we check for U.K. Prime Minister, the speaker, mr Speaker and see how these are treated too, along with numeric values 1000 1,000 01/01/2020\"\n",
    "print(my_tokenizer_lemma(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54d9019",
   "metadata": {},
   "source": [
    "## Program / Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c88295",
   "metadata": {},
   "source": [
    "### Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e8d92e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8084, 8)\n"
     ]
    }
   ],
   "source": [
    " # Load speeches data frame\n",
    "df = read_speeches_csv()\n",
    "# Clean data frame\n",
    "df_cleaned = speeches_clean(df)\n",
    "# Print dimensions\n",
    "print(df_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "99894f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#  (b) Generate object that splits data using stratified sampling, and random seed of 26\n",
    "splitter_obj = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 26) \n",
    "# Split data\n",
    "for train_index, test_index in splitter_obj.split(df_cleaned, df_cleaned['party']):\n",
    "    train = df_cleaned.iloc[train_index]\n",
    "    test = df_cleaned.iloc[test_index]\n",
    "# (b) Split target in both training and testing set\n",
    "y_train, y_test = train['party'], test['party']\n",
    "# (b) Create vectorised data for x objects\n",
    "'''\n",
    "Max features set to 3000\n",
    "stop_words, ngram = defined by parameters when function is called\n",
    "'''\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features = 3000, \n",
    "                             stop_words='english', \n",
    "                             ngram_range = (1,3),\n",
    "                             tokenizer = my_tokenizer_lemma)\n",
    "x_train = vectorizer.fit_transform(train['speech'])\n",
    "x_test = vectorizer.transform(test['speech'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bdc9e8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "[CV] END .............................C=0.001, max_iter=5000; total time=   0.5s\n",
      "[CV] END .............................C=0.001, max_iter=5000; total time=   0.5s\n",
      "[CV] END .............................C=0.001, max_iter=5000; total time=   0.5s\n",
      "[CV] END .............................C=0.001, max_iter=5000; total time=   0.5s\n",
      "[CV] END .............................C=0.001, max_iter=5000; total time=   0.5s\n",
      "[CV] END ..............................C=0.01, max_iter=5000; total time=   0.6s\n",
      "[CV] END ..............................C=0.01, max_iter=5000; total time=   0.7s\n",
      "[CV] END ..............................C=0.01, max_iter=5000; total time=   0.7s\n",
      "[CV] END ..............................C=0.01, max_iter=5000; total time=   0.5s\n",
      "[CV] END ..............................C=0.01, max_iter=5000; total time=   0.5s\n",
      "[CV] END ...............................C=0.1, max_iter=5000; total time=   0.7s\n",
      "[CV] END ...............................C=0.1, max_iter=5000; total time=   0.7s\n",
      "[CV] END ...............................C=0.1, max_iter=5000; total time=   0.7s\n",
      "[CV] END ...............................C=0.1, max_iter=5000; total time=   0.7s\n",
      "[CV] END ...............................C=0.1, max_iter=5000; total time=   0.7s\n",
      "[CV] END .................................C=1, max_iter=5000; total time=   0.9s\n",
      "[CV] END .................................C=1, max_iter=5000; total time=   1.1s\n",
      "[CV] END .................................C=1, max_iter=5000; total time=   1.1s\n",
      "[CV] END .................................C=1, max_iter=5000; total time=   1.1s\n",
      "[CV] END .................................C=1, max_iter=5000; total time=   1.1s\n",
      "[CV] END ................................C=10, max_iter=5000; total time=   1.8s\n",
      "[CV] END ................................C=10, max_iter=5000; total time=   1.8s\n",
      "[CV] END ................................C=10, max_iter=5000; total time=   2.3s\n",
      "[CV] END ................................C=10, max_iter=5000; total time=   1.9s\n",
      "[CV] END ................................C=10, max_iter=5000; total time=   2.0s\n",
      "[CV] END ..............................C=1000, max_iter=5000; total time=   2.1s\n",
      "[CV] END ..............................C=1000, max_iter=5000; total time=   2.9s\n",
      "[CV] END ..............................C=1000, max_iter=5000; total time=   3.1s\n",
      "[CV] END ..............................C=1000, max_iter=5000; total time=   2.9s\n",
      "[CV] END ..............................C=1000, max_iter=5000; total time=   2.3s\n",
      "[CV] END ...............................C=100, max_iter=5000; total time=   6.8s\n",
      "[CV] END ...............................C=100, max_iter=5000; total time=   7.0s\n",
      "[CV] END ...............................C=100, max_iter=5000; total time=   7.2s\n",
      "[CV] END ...............................C=100, max_iter=5000; total time=   6.5s\n",
      "[CV] END ...............................C=100, max_iter=5000; total time=   6.7s\n",
      "\n",
      "=== All macro F1 scores ===\n",
      "C=0.001, macro F1: 0.192\n",
      "C=0.01, macro F1: 0.520\n",
      "C=0.1, macro F1: 0.671\n",
      "C=1, macro F1: 0.670\n",
      "C=10, macro F1: 0.638\n",
      "C=100, macro F1: 0.635\n",
      "C=1000, macro F1: 0.635\n",
      "Best params: {'C': 0.1, 'max_iter': 5000}\n",
      "Best macro F1 (CV): 0.670542051710732\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.86      0.90      0.88       964\n",
      "                 Labour       0.76      0.69      0.73       463\n",
      "       Liberal Democrat       0.52      0.48      0.50        54\n",
      "Scottish National Party       0.70      0.71      0.70       136\n",
      "\n",
      "               accuracy                           0.81      1617\n",
      "              macro avg       0.71      0.69      0.70      1617\n",
      "           weighted avg       0.81      0.81      0.81      1617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c_initial = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "tuned = [0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68]\n",
    "param_grid = [{'C': c_initial,\n",
    "               'max_iter': [5000]}]\n",
    "\n",
    "svc = LinearSVC(class_weight='balanced')\n",
    "\n",
    "grid_search = GridSearchCV(estimator = svc,\n",
    "                           param_grid = param_grid,\n",
    "                           scoring = 'f1_macro',\n",
    "                           cv = 5,\n",
    "                           verbose = 2,\n",
    "                           n_jobs = -1)\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "print(\"\\n=== All macro F1 scores ===\")\n",
    "for mean, params in zip(grid_search.cv_results_['mean_test_score'], grid_search.cv_results_['params']):\n",
    "    print(f\"C={params['C']}, macro F1: {mean:.3f}\")\n",
    "\n",
    "print(\"Best params:\", grid_search.best_params_)\n",
    "print(\"Best macro F1 (CV):\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate best model on your held-out test:\n",
    "best_svc = grid_search.best_estimator_\n",
    "y_pred = best_svc.predict(x_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beca9905",
   "metadata": {},
   "source": [
    "### Train and test ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5d91d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to record the Macro Avg F1 score for each tested model\n",
    "f1_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee56249",
   "metadata": {},
   "source": [
    "#### Section C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ef754d",
   "metadata": {},
   "source": [
    "##### Model set 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2bb5bc",
   "metadata": {},
   "source": [
    "Train a Random Forest Model and SVM linear Kernel model:\n",
    "\n",
    "- Ngram: unigram only\n",
    "- Tokenizer: Default\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b62231c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Random Forest Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.73      0.98      0.84       964\n",
      "Scottish National Party       0.78      0.46      0.58       463\n",
      "                 Labour       0.00      0.00      0.00        54\n",
      "       Liberal Democrat       0.90      0.32      0.47       136\n",
      "\n",
      "               accuracy                           0.74      1617\n",
      "              macro avg       0.60      0.44      0.47      1617\n",
      "           weighted avg       0.73      0.74      0.70      1617\n",
      "\n",
      "F1 Macro Average Score: 0.47\n",
      "\n",
      "==================== SVC Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.85      0.92      0.88       964\n",
      "Scottish National Party       0.76      0.73      0.74       463\n",
      "                 Labour       1.00      0.22      0.36        54\n",
      "       Liberal Democrat       0.72      0.57      0.64       136\n",
      "\n",
      "               accuracy                           0.81      1617\n",
      "              macro avg       0.83      0.61      0.66      1617\n",
      "           weighted avg       0.81      0.81      0.80      1617\n",
      "\n",
      "F1 Macro Average Score: 0.66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "section_c, svm_model_c, rf_model_c  = ml_pipeline(data = df_cleaned)\n",
    "# Save results into a dictionary\n",
    "f1_results['f1_ma_rf_unigram'] =  round(section_c['rf']['macro avg']['f1-score'] ,2)\n",
    "f1_results['f1_ma_svc_unigram'] = round(section_c['svc']['macro avg']['f1-score'], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48db1089",
   "metadata": {},
   "source": [
    "#### Section D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f7cf60",
   "metadata": {},
   "source": [
    "##### Model Set 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55b9eba",
   "metadata": {},
   "source": [
    "Train a Random Forest Model and SVM linear Kernel model:\n",
    "\n",
    "- Ngram: unigram, bi-gram and tri-grams\n",
    "- Tokenizer: Default\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f6a784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Random Forest Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.71      0.97      0.82       964\n",
      "Scottish National Party       0.81      0.40      0.53       463\n",
      "                 Labour       0.00      0.00      0.00        54\n",
      "       Liberal Democrat       0.82      0.49      0.61       136\n",
      "\n",
      "               accuracy                           0.73      1617\n",
      "              macro avg       0.59      0.46      0.49      1617\n",
      "           weighted avg       0.73      0.73      0.69      1617\n",
      "\n",
      "F1 Macro Average Score: 0.49\n",
      "\n",
      "==================== SVC Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.87      0.90      0.89       964\n",
      "Scottish National Party       0.75      0.74      0.75       463\n",
      "                 Labour       0.53      0.37      0.43        54\n",
      "       Liberal Democrat       0.70      0.69      0.70       136\n",
      "\n",
      "               accuracy                           0.82      1617\n",
      "              macro avg       0.71      0.67      0.69      1617\n",
      "           weighted avg       0.81      0.82      0.82      1617\n",
      "\n",
      "F1 Macro Average Score: 0.69\n",
      "\n"
     ]
    }
   ],
   "source": [
    "section_d,  svm_model_d, rf_model_d = ml_pipeline(data = df_cleaned, ngram = (1,3))\n",
    "# Save results into a dictionary\n",
    "f1_results['f1_ma_rf_uni_bi_trigrams'] =  round(section_d['rf']['macro avg']['f1-score'] ,2)\n",
    "f1_results['f1_ma_svc_uni_bi_trigrams'] = round(section_d['svc']['macro avg']['f1-score'], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a782cab7",
   "metadata": {},
   "source": [
    "#### Section E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508aafcb",
   "metadata": {},
   "source": [
    "**Basic Tokenizer**\n",
    "\n",
    "`my_tokenizer_basic`\n",
    "\n",
    "- Removes special break characters, such as \\n, \\t etc\n",
    "- Removes any extra white spaces \n",
    "- Uses `nltk` word tokenizer to split the words into objects\n",
    "- Only keeps alphabetical objects, ignores numeric and punctuation marks\n",
    "- It keeps English stop words\n",
    "\n",
    "From the metrics below, we can see that this tokenizer did not improve performance on the model. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "538f5c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arguments:\n",
      "\tNgram: (1, 3)\n",
      "\tStop words: None\n",
      "\tTokenizer: my_tokenizer_basic\n",
      "\tClass Weights: balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Random Forest Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.71      0.98      0.82       964\n",
      "Scottish National Party       0.84      0.37      0.51       463\n",
      "                 Labour       0.00      0.00      0.00        54\n",
      "       Liberal Democrat       0.82      0.46      0.59       136\n",
      "\n",
      "               accuracy                           0.73      1617\n",
      "              macro avg       0.59      0.45      0.48      1617\n",
      "           weighted avg       0.73      0.73      0.68      1617\n",
      "\n",
      "==================== SVC Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.88      0.88      0.88       964\n",
      "Scottish National Party       0.73      0.74      0.73       463\n",
      "                 Labour       0.50      0.33      0.40        54\n",
      "       Liberal Democrat       0.68      0.72      0.70       136\n",
      "\n",
      "               accuracy                           0.81      1617\n",
      "              macro avg       0.70      0.67      0.68      1617\n",
      "           weighted avg       0.81      0.81      0.81      1617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "section_e_basic_t =  ml_pipeline(data = df_cleaned, ngram = (1,3), tokenizer = my_tokenizer_basic, class_weight='balanced')\n",
    "f1_results['f1_ma_rf_uni_bi_trigrams_basictoken'] =  round(section_e_basic_t['rf']['macro avg']['f1-score'] ,2)\n",
    "f1_results['f1_ma_svc_uni_bi_trigrams_basictoken'] = round(section_e_basic_t['svc']['macro avg']['f1-score'], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f573e19f",
   "metadata": {},
   "source": [
    "**Spacy/Contractions Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2d69afbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arguments:\n",
      "\tNgram: (1, 3)\n",
      "\tStop words: None\n",
      "\tTokenizer: my_tokenizer_spacy\n",
      "\tClass Weights: balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Random Forest Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.70      0.98      0.81       964\n",
      "Scottish National Party       0.82      0.34      0.48       463\n",
      "                 Labour       0.00      0.00      0.00        54\n",
      "       Liberal Democrat       0.81      0.41      0.55       136\n",
      "\n",
      "               accuracy                           0.72      1617\n",
      "              macro avg       0.58      0.43      0.46      1617\n",
      "           weighted avg       0.72      0.72      0.67      1617\n",
      "\n",
      "==================== SVC Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.88      0.88      0.88       964\n",
      "Scottish National Party       0.73      0.73      0.73       463\n",
      "                 Labour       0.50      0.33      0.40        54\n",
      "       Liberal Democrat       0.67      0.72      0.70       136\n",
      "\n",
      "               accuracy                           0.81      1617\n",
      "              macro avg       0.69      0.67      0.68      1617\n",
      "           weighted avg       0.81      0.81      0.81      1617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "section_e_spacy_t =  ml_pipeline(data = df_cleaned, ngram = (1,3), tokenizer = my_tokenizer_spacy, class_weight='balanced')\n",
    "f1_results['f1_ma_rf_uni_bi_trigrams_spacytoken'] =  round(section_e_spacy_t['rf']['macro avg']['f1-score'] ,2)\n",
    "f1_results['f1_ma_svc_uni_bi_trigrams_spacytoken'] = round(section_e_spacy_t['svc']['macro avg']['f1-score'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1159c705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== SVC Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.85      0.92      0.88       964\n",
      "Scottish National Party       0.75      0.74      0.74       463\n",
      "                 Labour       1.00      0.24      0.39        54\n",
      "       Liberal Democrat       0.73      0.54      0.62       136\n",
      "\n",
      "               accuracy                           0.81      1617\n",
      "              macro avg       0.83      0.61      0.66      1617\n",
      "           weighted avg       0.81      0.81      0.80      1617\n",
      "\n",
      "F1 Macro Average Score: 0.66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "section_e_mytoken, svm_model_e_mytoken, rf_model__e_mytoken =  ml_pipeline(data = df_cleaned, \n",
    "                                                                           ngram = (1,1), \n",
    "                                                                           tokenizer = my_tokenizer_contractions_clean, \n",
    "                                                                           class_weight='balanced', \n",
    "                                                                           best_model = True)\n",
    "\n",
    "f1_results['f1_ma_rf_uni_bi_trigrams_contractcleantoken'] =  round(section_e_mytoken['rf']['macro avg']['f1-score'] ,2)\n",
    "f1_results['f1_ma_svc_uni_bi_trigrams_contractcleantoken'] = round(section_e_mytoken['svc']['macro avg']['f1-score'], 2)\n",
    "\n",
    "#)1,3) stop words removed: svc.56\n",
    "#(1,2) stop words removed: svc.70\n",
    "#(1,1) stop words removed: svc.70\n",
    "\n",
    "#(1,3) no stop words removed: svc.68\n",
    "#(1,2) no stop words removed: svc.67\n",
    "#(1,1) no stop words removed: svc.70\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ea2cfea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arguments:\n",
      "\tNgram: (1, 3)\n",
      "\tStop words: english\n",
      "\tTokenizer: my_tokenizer_lemma\n",
      "\tClass Weights: balanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Random Forest Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.71      0.97      0.82       964\n",
      "Scottish National Party       0.82      0.38      0.52       463\n",
      "                 Labour       0.00      0.00      0.00        54\n",
      "       Liberal Democrat       0.86      0.48      0.61       136\n",
      "\n",
      "               accuracy                           0.73      1617\n",
      "              macro avg       0.59      0.46      0.49      1617\n",
      "           weighted avg       0.73      0.73      0.69      1617\n",
      "\n",
      "==================== SVC Performance ====================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Conservative       0.87      0.90      0.89       964\n",
      "Scottish National Party       0.77      0.74      0.75       463\n",
      "                 Labour       0.53      0.44      0.48        54\n",
      "       Liberal Democrat       0.71      0.71      0.71       136\n",
      "\n",
      "               accuracy                           0.82      1617\n",
      "              macro avg       0.72      0.70      0.71      1617\n",
      "           weighted avg       0.82      0.82      0.82      1617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/enmanuelmoreno/.local/share/virtualenvs/nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "section_e_lemma_t =  ml_pipeline(data = df_cleaned, ngram = (1,3), tokenizer = my_tokenizer_lemma, class_weight='balanced', stop_words = 'english')\n",
    "f1_results['f1_ma_rf_uni_bi_trigrams_lemmatoken'] =  round(section_e_lemma_t['rf']['macro avg']['f1-score'] ,2)\n",
    "f1_results['f1_ma_svc_uni_bi_trigrams_lemmatoken'] = round(section_e_lemma_t['svc']['macro avg']['f1-score'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "74fc4c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Macro Avg Score f1_ma_rf_unigram                                   Value:   0.45\n",
      "F1 Macro Avg Score f1_ma_svc_unigram                                  Value:   0.66\n",
      "F1 Macro Avg Score f1_ma_rf_unigram_balanced                          Value:   0.48\n",
      "F1 Macro Avg Score f1_ma_svc_unigram_balanced                         Value:   0.70\n",
      "F1 Macro Avg Score f1_ma_rf_uni_bi_trigrams                           Value:   0.48\n",
      "F1 Macro Avg Score f1_ma_svc_uni_bi_trigrams                          Value:   0.65\n",
      "F1 Macro Avg Score f1_ma_rf_uni_bi_trigrams_balanced                  Value:   0.49\n",
      "F1 Macro Avg Score f1_ma_svc_uni_bi_trigrams_balanced                 Value:   0.69\n",
      "F1 Macro Avg Score f1_ma_rf_uni_bi_trigrams_basictoken                Value:   0.48\n",
      "F1 Macro Avg Score f1_ma_svc_uni_bi_trigrams_basictoken               Value:   0.68\n",
      "F1 Macro Avg Score f1_ma_rf_uni_bi_trigrams_sentencetoken             Value:   0.31\n",
      "F1 Macro Avg Score f1_ma_svc_uni_bi_trigrams_sentencetoken            Value:   0.30\n",
      "F1 Macro Avg Score f1_ma_rf_uni_bi_trigrams_spacytoken                Value:   0.46\n",
      "F1 Macro Avg Score f1_ma_svc_uni_bi_trigrams_spacytoken               Value:   0.68\n",
      "F1 Macro Avg Score f1_ma_rf_uni_bi_trigrams_contractcleantoken        Value:   0.41\n",
      "F1 Macro Avg Score f1_ma_svc_uni_bi_trigrams_contractcleantoken       Value:   0.70\n",
      "F1 Macro Avg Score f1_ma_rf_uni_bi_trigrams_lemmatoken                Value:   0.49\n",
      "F1 Macro Avg Score f1_ma_svc_uni_bi_trigrams_lemmatoken               Value:   0.71\n",
      "F1 Macro Avg Score f1_ma_rf_uni_bi_trigrams_treebanktoken             Value:   0.48\n",
      "F1 Macro Avg Score f1_ma_svc_uni_bi_trigrams_treebanktoken            Value:   0.68\n"
     ]
    }
   ],
   "source": [
    "for key, value in f1_results.items():\n",
    "    print(f\"F1 Macro Avg Score {key:<50} Value: {value:6.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaaf746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-coursework-2024-25-enmanuelmorego-pEh8u7DC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
